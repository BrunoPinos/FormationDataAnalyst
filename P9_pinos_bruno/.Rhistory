plot(fit),
ggplot(data.frame(fit$residuals),aes(fit.residuals)) +
geom_histogram(aes(y=..count..), colour="blue", fill= "white")+
geom_vline(aes(xintercept=mean(fit.residuals), color="red"))+
xlab("Residuals values")+ ylab("Number of residuals"),
ggplot(data=analyses,aes(x=obs, y=levier))+
geom_bar(stat="identity",colour="steelblue")+
geom_hline(yintercept=seuil_levier,col="red")+
theme_minimal()+
xlab("Observation")+
ylab("Leviers")+
scale_x_continuous(breaks=seq(0,n,by=5)),
ggplot(data=analyses,aes(x=obs,y=rstudent))+
geom_bar(stat="identity",colour="steelblue")+
geom_hline(yintercept=-seuil_rstudent,col="red")+
geom_hline(yintercept=seuil_rstudent,col="red")+
theme_minimal()+
xlab("observation")+
ylab("Résidus studentisés")+
scale_x_continuous(breaks=seq(0,n,by=5)),
summary(fit),
bptest(fit),
vif(fit),
shapiro.test(fit$residuals),
ks.test(fit$residuals, "pnorm")
)
)
}
########################################################################
###On récupère les données de consomation
energie<-read.csv("energie.csv", sep = ",", encoding = "latin1")
###Je transforme la colonne mois en vecteur pour pouvoir les ordonner
energie$Mois<-energie$Mois%>%unlist()%>%as.vector()
#L'année 2020 comporte des données douteuses on les enlève
conso<-energie%>%
filter(Territoire == "France" & Mois < "2020-01")%>%
select(Date = Mois, Territoire, "Qualité", Conso = Consommation.totale)
#Je crée une colonne time qui est une clé primaire et qui me permettra
#d'étudier et de représenter la série temporelle
conso$time<-1:nrow(conso)
#J'affiche le début des colonnes data et conso de ma table
head(select(conso, Date, Consommation = Conso))
x<-select(conso, Date, Consommation = Conso)
#Je construit le graph de ma série temporelle(conso en fct de année)
ggplot(conso, aes(x = time, y = Conso)) +
geom_path(col = "red")+
scale_x_continuous(breaks=seq(1,96,12),
labels = c("2012","2013","2014","2015","2016","2017",
"2018","2019")) + xlab("Année")+
ylab("Consomation en TWh")
#Je récupère les données DJU de paris(~France)
DJU<-read.csv("DJU.csv", sep = ",", encoding = "latin1",
skip = 11)%>%rename("Année" = X)
#Je rajoute les données DJU à ma table principale
for (j in 0:7) {
for (i in 1:12) {
conso$DJU[i+j*12]<-DJU[9-j,i+1]
}
}
#Je crée une indicatrice mois dans ma table principale
for (i in 1:12){
su=rep(0,times=12)
su[i]=1
s=rep(su,times=8)
assign(paste("s",i,sep=""),s)
}
conso_lm<-cbind(conso,s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,s12)
head(conso_lm%>%select(-"Territoire", -"Qualité"))
#je crée un modèle prédictif pour expliquer la consomation
#à partir des mois de la DJU et du temps écoulé.
fit<-lm(Conso ~ time + s1 + s2 + s3 +s4 + s5 + s6 +
s7 + s8 + s9 + s10 + s11 + s12 - 1 + DJU, conso_lm)
#j'analyse le modèle
summary(fit)
#J'analyse les résidus du modèle
f_graph(fit, 14)
#J'ajoute une colonne qui donne la consomation corrigée de l'effet
#température
conso$Conso_adj<-conso$Conso - conso$DJU*fit$coefficients[["DJU"]]
#Je cré une table pour faire mes graphes où j'ai regroupé les différentes
#données de consomation dans la même colonne
conso_grph<-melt(data = conso, id.vars = c(1:3,5:6),
measure.vars = c(4,7))
#Je construit le graph qui représente la conso en fonction de l'année
#mais aussi la conso corrigé de l'effet température
ggplot(conso_grph, aes(x = time, y = value)) +
geom_line(aes(colour = variable))+
scale_x_continuous(breaks=seq(1,96,12),
labels = c("2012","2013","2014","2015","2016","2017",
"2018","2019"))+ xlab("Année")+
ylab("Consomation en Twh")
#Je transforme ma colonne conso corrigé effet température au format
#série temporelle
ts_conso_adj<-ts(conso$Conso_adj, start = c(2012, 1), end = c(2019, 12),
frequency = 12)
#J'utilise la fonction decompose pour étudier ma série temporelle
decomp_conso_adj<-decompose(ts_conso_adj)
plot(decomp_conso_adj)
#J'ajoute à ma table principale toutes les parties de ma consomation
#une colonne par partie
conso$trend<-decomp_conso_adj$trend
conso$seasonal<-decomp_conso_adj$seasonal
conso$random<-decomp_conso_adj$random
#Je crée une colonne avec la consomation desaisonalisé
conso$deseasonal<-conso$Conso_adj - conso$seasonal
#Je rejoute les nouvelles données à ma table pour les graphiques
conso_grph<-melt(data = conso, id.vars = c(1:3,5:6),
measure.vars = c(4,7:11))
#Je construit le graph de ma série corrigé de l'effet température
#et de ma série corrigé de l'effet température et désaisonalisé
ggplot(conso_grph%>%filter(variable == "deseasonal" |
variable == "Conso_adj"),
aes(x = time, y = value)) +
geom_line(aes(colour = variable))+
scale_x_continuous(breaks=seq(1,96,12),
labels = c("2012","2013","2014","2015","2016","2017",
"2018","2019"))+ xlab("Année")+
ylab("Consomation en Twh")
#J'utilise le lissage exponentiel Holt Winter pour effectuer des
#prédictions
hw<-ets(ts_conso_adj, model = "ZZZ")
#J'observe les prédictions
plot(hw)
pred_hw<-predict(hw,12)
plot(pred_hw)
#Je cré ensuite le graph de la prédiction sur les années connues puis
#2 années supplémentaires
ts.plot(pred_hw$x,
pred_hw$mean,
pred_hw$lower[,2],
pred_hw$upper[,2],
pred_hw$fitted,
xlab="Annee",ylab="Consomation",
col=c(1,2,3,3,2),lty=c(1,1,2,2),lwd=c(1,3,2,2))
#J'étudie l'autocorrelogram de ma série prédite
acf(pred_hw$residuals, lag.max=48)
#J'effectue un test Ljung-Box
Box.test(pred_hw$residuals, lag=12, type="Ljung-Box")
#tests variables
t_stat(model1)
#Je crée le meilleur modèles parmis les modèles testés,
#je l'analyse et le test encore une fois
model1<-Arima(ts_conso_adj,order=c(5,1,2),
list(order=c(0,1,1),period=12),
include.mean=TRUE,method="CSS-ML")
#analyse
summary(model1)
#tests variables
t_stat(model1)
#test autocorrélation résidu
Box.test.2(model1$residuals,nlag=c(6,12,18,24,30,36),
type="Ljung-Box",decim=5)
#test normalité résidus
shapiro.test(model1$residuals)
#graphe normalité des résidus
qplot(model1$residuals)
#Je valide le modele
View(conso)
View(conso)
head(conso[,c(1:7,11)])
x<-head(conso[,c(1:7,11)])
View(x)
#J'effectue une diférenciation de lag = 12
y_dif_12=diff(ts_conso_adj,lag=12,differences=1)
#J'analyse à nouveau l'autoc pour décider des coefficient AR ou d'une
#nouvelle différenciation
plot(acf(y_dif_12,lag.max=36,plot=FALSE),ylim=c(-1,1))
#J'analyse maintenant l'autoc partiel pour mes coef MA
plot(pacf(y_dif_12,lag.max=36,plot=FALSE),ylim=c(-1,1))
pmax = 1
qmax = 0
Pmax = 1
Qmax = 1
i<-1
c<-data.frame()
for (p in 0:pmax) {
for (q in 0:qmax) {
for (p12 in 0:Pmax) {
for (q12 in 0:Qmax) {
model1=try(Arima(ts_conso_adj,order=c(p,0,q),
list(order=c(p12,1,q12),period=12),
include.mean=TRUE,method="CSS-ML"),TRUE)
if (class(try(length(t_stat(model1)),TRUE)) == "integer"){
if (length(t_stat(model1)) == 0){
c[i,"nom_model"]<-paste("model(",p,"0",q,")(",p12,"0",q12,")",
sep = "")
c[i,"aic"]<-model1$aic
c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
i<-i+1
}
else if (length(t_stat(model1)[2,]) ==
try((t_stat(model1)[2,]<0.05)%>%as.numeric()%>%sum())) {
c[i,"nom_model"]<-paste("model(",p,"1",q,")(",p12,"1",q12,")",
sep = "")
c[i,"aic"]<-model1$aic
c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
i<-i+1
}
}
}
}
}
}
DT::datatable(c%>%arrange(aic))
###On télécharge les libraries utiles
library(dplyr)
library(ggplot2)
library(tidyr)
library(rstatix)
library(car)
library(lmtest)
library(forecast)
library(infer)
library(reshape2)
library(caschrono)
select<-dplyr::select
filter<-dplyr::filter
pmax = 1
qmax = 0
Pmax = 1
Qmax = 1
i<-1
c<-data.frame()
for (p in 0:pmax) {
for (q in 0:qmax) {
for (p12 in 0:Pmax) {
for (q12 in 0:Qmax) {
model1=try(Arima(ts_conso_adj,order=c(p,0,q),
list(order=c(p12,1,q12),period=12),
include.mean=TRUE,method="CSS-ML"),TRUE)
if (class(try(length(t_stat(model1)),TRUE)) == "integer"){
if (length(t_stat(model1)) == 0){
c[i,"nom_model"]<-paste("model(",p,"0",q,")(",p12,"0",q12,")",
sep = "")
c[i,"aic"]<-model1$aic
c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
i<-i+1
}
else if (length(t_stat(model1)[2,]) ==
try((t_stat(model1)[2,]<0.05)%>%as.numeric()%>%sum())) {
c[i,"nom_model"]<-paste("model(",p,"1",q,")(",p12,"1",q12,")",
sep = "")
c[i,"aic"]<-model1$aic
c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
i<-i+1
}
}
}
}
}
}
DT::datatable(c%>%arrange(aic))
pmax = 1
qmax = 0
Pmax = 1
Qmax = 1
i<-1
c<-data.frame()
for (p in 0:pmax) {
for (q in 0:qmax) {
for (p12 in 0:Pmax) {
for (q12 in 0:Qmax) {
model1=try(Arima(ts_conso_adj,order=c(p,0,q),
list(order=c(p12,1,q12),period=12),
include.mean=TRUE,method="CSS-ML"),TRUE)
if (class(try(length(t_stat(model1)),TRUE)) == "integer"){
if (length(t_stat(model1)) == 0){
c[i,"nom_model"]<-paste("model(",p,"0",q,")(",p12,"1",q12,")",
sep = "")
c[i,"aic"]<-model1$aic
c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
i<-i+1
}
else if (length(t_stat(model1)[2,]) ==
try((t_stat(model1)[2,]<0.05)%>%as.numeric()%>%sum())) {
c[i,"nom_model"]<-paste("model(",p,"0",q,")(",p12,"1",q12,")",
sep = "")
c[i,"aic"]<-model1$aic
c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
i<-i+1
}
}
}
}
}
}
DT::datatable(c%>%arrange(aic))
pmax = 1
qmax = 2
Pmax = 1
Qmax = 1
i<-1
c<-data.frame()
for (p in 0:pmax) {
for (q in 0:qmax) {
for (p12 in 0:Pmax) {
for (q12 in 0:Qmax) {
model1=try(Arima(ts_conso_adj,order=c(p,0,q),
list(order=c(p12,1,q12),period=12),
include.mean=TRUE,method="CSS-ML"),TRUE)
if (class(try(length(t_stat(model1)),TRUE)) == "integer"){
if (length(t_stat(model1)) == 0){
c[i,"nom_model"]<-paste("model(",p,"0",q,")(",p12,"1",q12,")",
sep = "")
c[i,"aic"]<-model1$aic
c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
i<-i+1
}
else if (length(t_stat(model1)[2,]) ==
try((t_stat(model1)[2,]<0.05)%>%as.numeric()%>%sum())) {
c[i,"nom_model"]<-paste("model(",p,"0",q,")(",p12,"1",q12,")",
sep = "")
c[i,"aic"]<-model1$aic
c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
i<-i+1
}
}
}
}
}
}
DT::datatable(c%>%arrange(aic))
pmax = 5
qmax = 5
Pmax = 3
Qmax = 3
i<-1
c<-data.frame()
for (p in 0:pmax) {
for (q in 0:qmax) {
for (p12 in 0:Pmax) {
for (q12 in 0:Qmax) {
model1=try(Arima(ts_conso_adj,order=c(p,0,q),
list(order=c(p12,1,q12),period=12),
include.mean=TRUE,method="CSS-ML"),TRUE)
if (class(try(length(t_stat(model1)),TRUE)) == "integer"){
if (length(t_stat(model1)) == 0){
c[i,"nom_model"]<-paste("model(",p,"0",q,")(",p12,"1",q12,")",
sep = "")
c[i,"aic"]<-model1$aic
c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
i<-i+1
}
else if (length(t_stat(model1)[2,]) ==
try((t_stat(model1)[2,]<0.05)%>%as.numeric()%>%sum())) {
c[i,"nom_model"]<-paste("model(",p,"0",q,")(",p12,"1",q12,")",
sep = "")
c[i,"aic"]<-model1$aic
c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
i<-i+1
}
}
}
}
}
}
DT::datatable(c%>%arrange(aic))
auto.arima(ts_conso_adj)
pmax = 1
qmax = 1
Pmax = 0
Qmax = 1
i<-1
c<-data.frame()
for (p in 0:pmax) {
for (q in 0:qmax) {
for (p12 in 0:Pmax) {
for (q12 in 0:Qmax) {
model1=try(Arima(ts_conso_adj,order=c(p,0,q),
list(order=c(p12,1,q12),period=12),
include.mean=TRUE,method="CSS-ML"),TRUE)
if (class(try(length(t_stat(model1)),TRUE)) == "integer"){
if (length(t_stat(model1)) == 0){
c[i,"nom_model"]<-paste("model(",p,"0",q,")(",p12,"1",q12,")",
sep = "")
c[i,"aic"]<-model1$aic
c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
i<-i+1
}
else if (length(t_stat(model1)[2,]) ==
try((t_stat(model1)[2,]<0.05)%>%as.numeric()%>%sum())) {
c[i,"nom_model"]<-paste("model(",p,"0",q,")(",p12,"1",q12,")",
sep = "")
c[i,"aic"]<-model1$aic
c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
i<-i+1
}
}
}
}
}
}
DT::datatable(c%>%arrange(aic))
pmax = 1 qmax = 1
pmax = 1, qmax = 1
View(c)
#J'effectue une diférenciation de lag = 12
y_dif_12=diff(ts_conso_adj,lag=12,differences=1)
#J'analyse à nouveau l'autoc pour décider des coefficient AR ou d'une
#nouvelle différenciation
plot(acf(y_dif_12,lag.max=36,plot=FALSE),ylim=c(-1,1))
#J'analyse maintenant l'autoc partiel pour mes coef MA
plot(pacf(y_dif_12,lag.max=36,plot=FALSE),ylim=c(-1,1))
pmax = 4
qmax = 4
Pmax = 0
Qmax = 1
i<-1
c<-data.frame()
for (p in 0:pmax) {
for (q in 0:qmax) {
for (p12 in 0:Pmax) {
for (q12 in 0:Qmax) {
model1=try(Arima(ts_conso_adj,order=c(p,0,q),
list(order=c(p12,1,q12),period=12),
include.mean=TRUE,method="CSS-ML"),TRUE)
if (class(try(length(t_stat(model1)),TRUE)) == "integer"){
if (length(t_stat(model1)) == 0){
c[i,"nom_model"]<-paste("model(",p,"0",q,")(",p12,"1",q12,")",
sep = "")
c[i,"aic"]<-model1$aic
c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
i<-i+1
}
else if (length(t_stat(model1)[2,]) ==
try((t_stat(model1)[2,]<0.05)%>%as.numeric()%>%sum())) {
c[i,"nom_model"]<-paste("model(",p,"0",q,")(",p12,"1",q12,")",
sep = "")
c[i,"aic"]<-model1$aic
c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
i<-i+1
}
}
}
}
}
}
DT::datatable(c%>%arrange(aic))
View(c)
#Je crée le meilleur modèles parmis les modèles testés,
#je l'analyse et le test encore une fois
model1<-Arima(ts_conso_adj,order=c(2,0,3),
list(order=c(0,1,1),period=12),
include.mean=TRUE,method="CSS-ML")
#analyse
summary(model1)
#tests variables
t_stat(model1)
#test autocorrélation résidu
Box.test.2(model1$residuals,nlag=c(6,12,18,24,30,36),
type="Ljung-Box",decim=5)
#test normalité résidus
shapiro.test(model1$residuals)
#graphe normalité des résidus
qplot(model1$residuals)
#Je valide le modele
#Je crée le meilleur modèles parmis les modèles testés,
#je l'analyse et le test encore une fois
model1<-Arima(ts_conso_adj,order=c(0,0,0),
list(order=c(0,1,1),period=12),
include.mean=TRUE,method="CSS-ML")
#analyse
summary(model1)
#tests variables
t_stat(model1)
#test autocorrélation résidu
Box.test.2(model1$residuals,nlag=c(6,12,18,24,30,36),
type="Ljung-Box",decim=5)
#test normalité résidus
shapiro.test(model1$residuals)
#graphe normalité des résidus
qplot(model1$residuals)
#Je valide le modele
model1$bic
pmax = 4
qmax = 4
Pmax = 0
Qmax = 1
i<-1
c<-data.frame()
for (p in 0:pmax) {
for (q in 0:qmax) {
for (p12 in 0:Pmax) {
for (q12 in 0:Qmax) {
model1=try(Arima(ts_conso_adj,order=c(p,0,q),
list(order=c(p12,1,q12),period=12),
include.mean=TRUE,method="CSS-ML"),TRUE)
if (class(try(length(t_stat(model1)),TRUE)) == "integer"){
if (length(t_stat(model1)) == 0){
c[i,"nom_model"]<-paste("model(",p,"0",q,")(",p12,"1",q12,")",
sep = "")
c[i,"aic"]<-model1$aic
c[i,"bic"]<-model1$bic
c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
i<-i+1
}
else if (length(t_stat(model1)[2,]) ==
try((t_stat(model1)[2,]<0.05)%>%as.numeric()%>%sum())) {
c[i,"nom_model"]<-paste("model(",p,"0",q,")(",p12,"1",q12,")",
sep = "")
c[i,"aic"]<-model1$aic
c[i,"bic"]<-model1$bic
c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
i<-i+1
}
}
}
}
}
}
DT::datatable(c%>%arrange(aic))
View(c)
