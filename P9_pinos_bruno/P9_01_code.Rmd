---
title: "P8"
author: "brunop31"
date: "18/08/2020"
output: html_document
---
```{r, warning=FALSE, message=FALSE}
###On télécharge les libraries utiles
library(dplyr)
library(ggplot2)
library(tidyr)
library(rstatix)
library(car)
library(lmtest)
library(forecast)
library(infer)
library(reshape2)
library(caschrono)

select<-dplyr::select
filter<-dplyr::filter
```

```{r, fonction pour faire les graphes et tests}
###fonction########################################################

###On crée une fonction pour analyser les regressions linéaires
f_graph<- function(fit,p){

df_function<-fit$model  
alpha <- 0.05
n <- dim(df_function)[1]
analyses <- data.frame(obs= 1:n)
analyses$levier <- hat(model.matrix(fit))
seuil_levier <- 2*p/n

analyses$rstudent <- rstudent(fit)
seuil_rstudent <- qt(1-alpha/2,n-p-1)

influence <- influence.measures(fit)
names(influence)
colnames(influence$infmat)

analyses$dcook <- influence$infmat[,"cook.d"]
seuil_dcook <- 4/(n-p)

layout(matrix(1:4, 2, 2))


return(
  list(
   plot(fit),
    
    ggplot(data.frame(fit$residuals),aes(fit.residuals)) + 
 geom_histogram(aes(y=..count..), colour="blue", fill= "white")+
  geom_vline(aes(xintercept=mean(fit.residuals), color="red"))+
  xlab("Residuals values")+ ylab("Number of residuals"),
    
ggplot(data=analyses,aes(x=obs, y=levier))+
   geom_bar(stat="identity",colour="steelblue")+
   geom_hline(yintercept=seuil_levier,col="red")+
   theme_minimal()+
   xlab("Observation")+
   ylab("Leviers")+
   scale_x_continuous(breaks=seq(0,n,by=5)),

ggplot(data=analyses,aes(x=obs,y=rstudent))+
  geom_bar(stat="identity",colour="steelblue")+
  geom_hline(yintercept=-seuil_rstudent,col="red")+
  geom_hline(yintercept=seuil_rstudent,col="red")+
  theme_minimal()+
  xlab("observation")+
  ylab("Résidus studentisés")+
  scale_x_continuous(breaks=seq(0,n,by=5)),

summary(fit),

bptest(fit),

vif(fit),

shapiro.test(fit$residuals),

ks.test(fit$residuals, "pnorm")
)
)
}

########################################################################
```

```{r}
###On récupère les données de consomation
energie<-read.csv("energie.csv", sep = ",", encoding = "latin1")

###Je transforme la colonne mois en vecteur pour pouvoir les ordonner
energie$Mois<-energie$Mois%>%unlist()%>%as.vector()

#L'année 2020 comporte des données douteuses on les enlève
conso<-energie%>%
  filter(Territoire == "France" & Mois < "2020-01")%>%
  select(Date = Mois, Territoire, "Qualité", Conso = Consommation.totale)

#Je crée une colonne time qui est une clé primaire et qui me permettra
#d'étudier et de représenter la série temporelle 
conso$time<-1:nrow(conso)

#J'affiche le début des colonnes data et conso de ma table
head(select(conso, Date, Consommation = Conso))

x<-select(conso, Date, Consommation = Conso)
#Je construit le graph de ma série temporelle(conso en fct de année)
ggplot(conso, aes(x = time, y = Conso)) + 
  geom_path(col = "red")+ 
  scale_x_continuous(breaks=seq(1,96,12),
                   labels = c("2012","2013","2014","2015","2016","2017",
                              "2018","2019")) + xlab("Année")+
                    ylab("Consomation en TWh")
```

```{r}
#Je récupère les données DJU de paris(~France)
DJU<-read.csv("DJU.csv", sep = ",", encoding = "latin1",
              skip = 11)%>%rename("Année" = X)



#Je rajoute les données DJU à ma table principale
for (j in 0:7) {
for (i in 1:12) {
  conso$DJU[i+j*12]<-DJU[9-j,i+1]
}
}

#Je crée une indicatrice mois dans ma table principale
for (i in 1:12){
  su=rep(0,times=12)
  su[i]=1
  s=rep(su,times=8)
  assign(paste("s",i,sep=""),s)
}

conso_lm<-cbind(conso,s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,s12)

head(conso_lm%>%select(-"Territoire", -"Qualité"))
```

```{r}
#je crée un modèle prédictif pour expliquer la consomation 
#à partir des mois de la DJU et du temps écoulé.
fit<-lm(Conso ~ time + s1 + s2 + s3 +s4 + s5 + s6 +
          s7 + s8 + s9 + s10 + s11 + s12 - 1 + DJU, conso_lm)

#j'analyse le modèle
summary(fit)
```

```{r}
#J'analyse les résidus du modèle
f_graph(fit, 14)
```

```{r, warning=FALSE}
#J'ajoute une colonne qui donne la consomation corrigée de l'effet
#température
conso$Conso_adj<-conso$Conso - conso$DJU*fit$coefficients[["DJU"]]

#Je cré une table pour faire mes graphes où j'ai regroupé les différentes
#données de consomation dans la même colonne
conso_grph<-melt(data = conso, id.vars = c(1:3,5:6), 
                 measure.vars = c(4,7))

#Je construit le graph qui représente la conso en fonction de l'année
#mais aussi la conso corrigé de l'effet température
ggplot(conso_grph, aes(x = time, y = value)) + 
  geom_line(aes(colour = variable))+ 
  scale_x_continuous(breaks=seq(1,96,12),
                   labels = c("2012","2013","2014","2015","2016","2017",
                              "2018","2019"))+ xlab("Année")+
                    ylab("Consomation en Twh")
```

```{r}
#Je transforme ma colonne conso corrigé effet température au format 
#série temporelle
ts_conso_adj<-ts(conso$Conso_adj, start = c(2012, 1), end = c(2019, 12),
                 frequency = 12)


#J'utilise la fonction decompose pour étudier ma série temporelle
decomp_conso_adj<-decompose(ts_conso_adj)
plot(decomp_conso_adj)
```

```{r, warning=FALSE}
#J'ajoute à ma table principale toutes les parties de ma consomation
#une colonne par partie
conso$trend<-decomp_conso_adj$trend
conso$seasonal<-decomp_conso_adj$seasonal

conso$random<-decomp_conso_adj$random

#Je crée une colonne avec la consommation dessaisonalisée
conso$deseasonal<-conso$Conso_adj - conso$seasonal

#Je rejoute les nouvelles données à ma table pour les graphiques
conso_grph<-melt(data = conso, id.vars = c(1:3,5:6), 
                 measure.vars = c(4,7:11))

#Je construit le graph de ma série corrigé de l'effet température
#et de ma série corrigé de l'effet température et désaisonalisé
ggplot(conso_grph%>%filter(variable == "deseasonal" |
                             variable == "Conso_adj"),
       aes(x = time, y = value)) + 
  geom_line(aes(colour = variable))+ 
  scale_x_continuous(breaks=seq(1,96,12),
                   labels = c("2012","2013","2014","2015","2016","2017",
                              "2018","2019"))+ xlab("Année")+
                    ylab("Consomation en Twh") 

x<-head(conso[,c(1:7,11)])
```


```{r}
#J'utilise le lissage exponentiel Holt Winter pour effectuer des
#prédictions
hw<-ets(ts_conso_adj, model = "ZZZ")

#J'observe les prédictions
plot(hw)
pred_hw<-predict(hw,12)
plot(pred_hw)

#Je cré ensuite le graph de la prédiction sur les années connues puis 
#2 années supplémentaires
ts.plot(pred_hw$x,
        pred_hw$mean,
        pred_hw$lower[,2],
        pred_hw$upper[,2],
        pred_hw$fitted,
        xlab="Annee",ylab="Consomation",
        col=c(1,2,3,3,2),lty=c(1,1,2,2),lwd=c(1,3,2,2))

```
```{r}
#J'étudie l'autocorrelogram de ma série prédite
acf(pred_hw$residuals, lag.max=48)

#test autocorrélation résidu
Box.test.2(pred_hw$residuals,nlag=c(6,12,18,24,30,36),
           type="Ljung-Box",decim=5)

#test normalité résidus
shapiro.test(pred_hw$residuals)

#graphe normalité des résidus
qplot(pred_hw$residuals)

#J'analyse graphiquement les résidus
plot(pred_hw$residuals)

#J'analyse mon modèle
summary(hw)
```


```{r, SARIMA}
###SARIMA#######################################################

#J'utilise maintenant un modèle SARIMA pour effectuer mes prédictions

#J'étudie l'autocorrelogramme de ma série pour étudier comment la série
#doit être différenciée
acf(ts_conso_adj,lag.max=72, plot=TRUE)
```



```{r}
#J'effectue une différenciation de lag 1
y_dif_1=diff(ts_conso_adj,lag=1,differences=1)
#J'analyse l'autoc
plot(acf(y_dif_1,lag.max=36,plot=FALSE),ylim=c(-1,1))
```

```{r}
#Je réalise une différenciation de lag 12 en plus de la lag 1
y_dif_1_12=diff(y_dif_1,lag=12, differences = 1)

#J'analyse encore l'autoc pour les coefs AR
plot(acf(y_dif_1_12,lag.max=36,plot=FALSE),ylim=c(-1,1))
```


```{r}
#j'analyse l'autoc partiel pour les coefs MA
plot(pacf(y_dif_1_12,lag.max=36,plot=FALSE),ylim=c(-1,1))
```

```{r}
pmax = 5
qmax = 2
Pmax = 0
Qmax = 1
i<-1
c<-data.frame()

for (p in 0:pmax) {
  for (q in 0:qmax) {
    for (p12 in 0:Pmax) {
      for (q12 in 0:Qmax) {
        model1=try(Arima(ts_conso_adj,order=c(p,1,q),
             list(order=c(p12,1,q12),period=12),
             include.mean=TRUE,method="CSS-ML"),TRUE)
        if (class(try(length(t_stat(model1)),TRUE)) == "integer"){
        if (length(t_stat(model1)) == 0){
        c[i,"nom_model"]<-paste("model(",p,"1",q,")(",p12,"1",q12,")",
                                    sep = "")
        c[i,"aic"]<-model1$aic
        c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
        i<-i+1
        }
        else if (length(t_stat(model1)[2,]) ==
          try((t_stat(model1)[2,]<0.05)%>%as.numeric()%>%sum())) {
        c[i,"nom_model"]<-paste("model(",p,"1",q,")(",p12,"1",q12,")",
                                    sep = "")
        c[i,"aic"]<-model1$aic
        c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
        i<-i+1
        }
        }
      }
    }
  }
}

DT::datatable(c%>%arrange(aic))
```

```{r}
#Je crée le meilleur modèles parmis les modèles testés,
#je l'analyse et le test encore une fois
model1<-Arima(ts_conso_adj,order=c(0,0,0),
             list(order=c(0,1,1),period=12),
             include.mean=TRUE,method="CSS-ML")

#analyse
summary(model1)

#tests variables
t_stat(model1)

#test autocorrélation résidu
Box.test.2(model1$residuals,nlag=c(6,12,18,24,30,36),
           type="Ljung-Box",decim=5)

#test normalité résidus
shapiro.test(model1$residuals)

#graphe normalité des résidus
qplot(model1$residuals)

#Je valide le modele
```


```{r}
#J'utilise une fonction qui permet de trouver des modèles performants
#de façon automatique
model2<-auto.arima(ts_conso_adj)

#c'est le modèle (000)(011) qui est trouvé par la fonction

#J'analyse et test le modèle
summary(model2)

t_stat(model2)

Box.test.2(model2$residuals,nlag=c(6,12,18,24,30,36),
           type="Ljung-Box",decim=5)

shapiro.test(model2$residuals)

qplot(model2$residuals)

#le model1 est plus performant je le conserve
```
```{r}
#J'effectue une prédiction avec le modèle choisi
pred_model1=forecast(model1,h=12,level=95)

#Je cré ensuite le graph de la prédiction sur les années connues puis 
#1 année supplémentaires
ts.plot(pred_model1$x,
        pred_model1$mean,
        pred_model1$lower,
        pred_model1$upper,
        pred_model1$fitted,
        xlab="Annee",ylab="Consomation",
        col=c(1,2,3,3,2),lty=c(1,1,2,2),lwd=c(1,3,2,2))
```

```{r}
#J'effectue une prédiction avec le modèle trouvé automatiquement
pred_model2=forecast(model2,h=12,level=95)

#Je cré ensuite le graph de la prédiction sur les années connues puis 
#1 année supplémentaires
ts.plot(pred_model2$x,
        pred_model2$mean,
        pred_model2$lower,
        pred_model2$upper,
        pred_model2$fitted,
        xlab="Annee",ylab="Consomation",
        col=c(1,2,3,3,2),lty=c(1,1,2,2),lwd=c(1,3,2,2))

```

```{r}
#J'effectue une diférenciation de lag = 12
y_dif_12=diff(ts_conso_adj,lag=12,differences=1)

#J'analyse à nouveau l'autoc pour décider des coefficient AR ou d'une 
#nouvelle différenciation
plot(acf(y_dif_12,lag.max=36,plot=FALSE),ylim=c(-1,1))
```
```{r}
#J'analyse maintenant l'autoc partiel pour mes coef MA
plot(pacf(y_dif_12,lag.max=36,plot=FALSE),ylim=c(-1,1))
```

```{r}
pmax = 4
qmax = 4
Pmax = 0
Qmax = 1
i<-1
c<-data.frame()

for (p in 0:pmax) {
  for (q in 0:qmax) {
    for (p12 in 0:Pmax) {
      for (q12 in 0:Qmax) {
        model1=try(Arima(ts_conso_adj,order=c(p,0,q),
             list(order=c(p12,1,q12),period=12),
             include.mean=TRUE,method="CSS-ML"),TRUE)
        if (class(try(length(t_stat(model1)),TRUE)) == "integer"){
        if (length(t_stat(model1)) == 0){
        c[i,"nom_model"]<-paste("model(",p,"0",q,")(",p12,"1",q12,")",
                                    sep = "")
        c[i,"aic"]<-model1$aic
        c[i,"bic"]<-model1$bic
        c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
        i<-i+1
        }
        else if (length(t_stat(model1)[2,]) ==
          try((t_stat(model1)[2,]<0.05)%>%as.numeric()%>%sum())) {
        c[i,"nom_model"]<-paste("model(",p,"0",q,")(",p12,"1",q12,")",
                                    sep = "")
        c[i,"aic"]<-model1$aic
        c[i,"bic"]<-model1$bic
        c[i,"RMCE"]<-(model1$residuals)^2%>%mean()%>%.^0.5
        i<-i+1
        }
        }
      }
    }
  }
}

DT::datatable(c%>%arrange(aic))
```