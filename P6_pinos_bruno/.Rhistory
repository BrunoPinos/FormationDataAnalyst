res.hcpc <- HCPC(res.pca, graph = FALSE, nb.par = 200, nb.clust = 2)
fviz_dend(res.hcpc,
k = 2,
cex = 0.7,                     # Taille du text
palette = "jco",               # Palette de couleur ?ggpubr::ggpar
rect = TRUE, rect_fill = TRUE, # Rectangle autour des groupes
rect_border = "jco",           # Couleur du rectangle
labels_track_height = 0.8      # Augment l'espace pour le texte
)
fviz_cluster(res.hcpc,
show.clust.cent = TRUE, # Show cluster centers
palette = "jco",         # Color palette see ?ggpubr::ggpar
ggtheme = theme_minimal(),
main = "Factor map"
)
res.hcpc$data.clust$clust<-
res.hcpc$data.clust$clust%>%factor(labels = c("2","1"))
###Je calcul la réussite de cette classification
mean(res.hcpc$data.clust$clust == df$is_genuine%>%as.numeric())
fviz_cluster(res.hcpc,
show.clust.cent = TRUE, # Show cluster centers
palette = "jco",         # Color palette see ?ggpubr::ggpar
ggtheme = theme_minimal(),
main = "Factor map"
)
###Je calcul la réussite de cette classification
mean(res.km$cluster == df$is_genuine%>%as.numeric())
0.9823529*170
i = 1
r = data.frame(mean_a = 0, mean_b = 0, mean_c = 0)
for (i in 1 : 100) {
training.samples <- df$is_genuine %>%
createDataPartition(p = 0.7, list = FALSE)
train.data <- df[training.samples, ]
test.data <- df[-training.samples, ]
# Estimate preprocessing parameters
preproc.param <- train.data %>%
preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)
# Fit the model
model1 <- lda(is_genuine~., data = train.transformed)
# Make predictions
predictions <- model1 %>% predict(test.transformed)
# Model accuracy
a<-mean(predictions$class==test.transformed$is_genuine)
# Fit the model
model2 <- glm(is_genuine~ length + margin_low + margin_up,
family="binomial",data= train.transformed)
probabilities <- model2 %>% predict(test.transformed, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "True", "False")
b<-mean(predicted.classes == test.transformed$is_genuine)
# Fit the model
model3 <- glm(is_genuine~ .,family="binomial",data= train.transformed)
probabilities <- model0 %>% predict(test.transformed, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "True", "False")
c<-mean(predicted.classes == test.transformed$is_genuine)
r$mean_a<-r$mean_a + a
r$mean_b<-r$mean_b + b
r$mean_b<-r$mean_c + c
i = i+1
}
i = 1
r = data.frame(mean_a = 0, mean_b = 0, mean_c = 0)
for (i in 1 : 100) {
training.samples <- df$is_genuine %>%
createDataPartition(p = 0.7, list = FALSE)
train.data <- df[training.samples, ]
test.data <- df[-training.samples, ]
# Estimate preprocessing parameters
preproc.param <- train.data %>%
preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)
# Fit the model
model1 <- lda(is_genuine~., data = train.transformed)
# Make predictions
predictions <- model1 %>% predict(test.transformed)
# Model accuracy
a<-mean(predictions$class==test.transformed$is_genuine)
# Fit the model
model2 <- glm(is_genuine~ length + margin_low + margin_up,
family="binomial",data= train.transformed)
probabilities <- model2 %>% predict(test.transformed, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "True", "False")
b<-mean(predicted.classes == test.transformed$is_genuine)
# Fit the model
model3 <- glm(is_genuine~ .,family="binomial",data= train.transformed)
probabilities <- model3 %>% predict(test.transformed, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "True", "False")
c<-mean(predicted.classes == test.transformed$is_genuine)
r$mean_a<-r$mean_a + a
r$mean_b<-r$mean_b + b
r$mean_b<-r$mean_c + c
i = i+1
}
View(r)
i = 1
r = data.frame(mean_a = 0, mean_b = 0, mean_c = 0)
for (i in 1 : 100) {
training.samples <- df$is_genuine %>%
createDataPartition(p = 0.7, list = FALSE)
train.data <- df[training.samples, ]
test.data <- df[-training.samples, ]
# Estimate preprocessing parameters
preproc.param <- train.data %>%
preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)
# Fit the model
model1 <- lda(is_genuine~., data = train.transformed)
# Make predictions
predictions <- model1 %>% predict(test.transformed)
# Model accuracy
a<-mean(predictions$class==test.transformed$is_genuine)
# Fit the model
model2 <- glm(is_genuine~ length + margin_low + margin_up,
family="binomial",data= train.transformed)
probabilities <- model2 %>% predict(test.transformed, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "True", "False")
b<-mean(predicted.classes == test.transformed$is_genuine)
# Fit the model
model3 <- glm(is_genuine~ .,family="binomial",data= train.transformed)
probabilities <- model3 %>% predict(test.transformed, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "True", "False")
c<-mean(predicted.classes == test.transformed$is_genuine)
r$mean_a<-r$mean_a + a
r$mean_b<-r$mean_b + b
r$mean_c<-r$mean_c + c
i = i+1
}
View(r)
i = 1
r = data.frame(mean_a = 0, mean_b = 0, mean_c = 0)
for (i in 1 : 100) {
training.samples <- df$is_genuine %>%
createDataPartition(p = 0.7, list = FALSE)
train.data <- df[training.samples, ]
test.data <- df[-training.samples, ]
# Estimate preprocessing parameters
preproc.param <- train.data %>%
preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)
# Fit the model
model1 <- lda(is_genuine~., data = train.transformed)
# Make predictions
predictions <- model1 %>% predict(test.transformed)
# Model accuracy
a<-mean(predictions$class==test.transformed$is_genuine)
# Fit the model
model2 <- glm(is_genuine~ length + margin_low + margin_up,
family="binomial",data= train.transformed)
probabilities <- model2 %>% predict(test.transformed, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "True", "False")
b<-mean(predicted.classes == test.transformed$is_genuine)
# Fit the model
model3 <- glm(is_genuine~ .,family="binomial",data= train.transformed)
probabilities <- model3 %>% predict(test.transformed, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "True", "False")
c<-mean(predicted.classes == test.transformed$is_genuine)
r$mean_a<-r$mean_a + a
r$mean_b<-r$mean_b + b
r$mean_c<-r$mean_c + c
i = i+1
}
```{r, warning= FALSE}
i = 1
r = data.frame(mean_a = 0, mean_b = 0, mean_c = 0)
for (i in 1 : 100) {
training.samples <- df$is_genuine %>%
createDataPartition(p = 0.7, list = FALSE)
train.data <- df[training.samples, ]
test.data <- df[-training.samples, ]
# Estimate preprocessing parameters
preproc.param <- train.data %>%
preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)
# Fit the model
model1 <- lda(is_genuine~., data = train.transformed)
# Make predictions
predictions <- model1 %>% predict(test.transformed)
# Model accuracy
a<-mean(predictions$class==test.transformed$is_genuine)
# Fit the model
model2 <- glm(is_genuine~ length + margin_low + margin_up,
family="binomial",data= train.transformed)
probabilities <- model2 %>% predict(test.transformed, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "True", "False")
b<-mean(predicted.classes == test.transformed$is_genuine)
# Fit the model
model3 <- glm(is_genuine~ .,family="binomial",data= train.transformed)
probabilities <- model3 %>% predict(test.transformed, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "True", "False")
c<-mean(predicted.classes == test.transformed$is_genuine)
r$mean_a<-r$mean_a + a
r$mean_b<-r$mean_b + b
r$mean_c<-r$mean_c + c
i = i+1
}
i = 1
r = data.frame(mean_a = 0, mean_b = 0, mean_c = 0)
for (i in 1 : 1000) {
training.samples <- df$is_genuine %>%
createDataPartition(p = 0.7, list = FALSE)
train.data <- df[training.samples, ]
test.data <- df[-training.samples, ]
# Estimate preprocessing parameters
preproc.param <- train.data %>%
preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)
# Fit the model
model1 <- lda(is_genuine~., data = train.transformed)
# Make predictions
predictions <- model1 %>% predict(test.transformed)
# Model accuracy
a<-mean(predictions$class==test.transformed$is_genuine)
# Fit the model
model2 <- glm(is_genuine~ length + margin_low + margin_up,
family="binomial",data= train.transformed)
probabilities <- model2 %>% predict(test.transformed, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "True", "False")
b<-mean(predicted.classes == test.transformed$is_genuine)
# Fit the model
model3 <- glm(is_genuine~ .,family="binomial",data= train.transformed)
probabilities <- model3 %>% predict(test.transformed, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "True", "False")
c<-mean(predicted.classes == test.transformed$is_genuine)
r$mean_a<-r$mean_a + a
r$mean_b<-r$mean_b + b
r$mean_c<-r$mean_c + c
i = i+1
}
r$mean_a<-r$mean_a/(i-1)
r$mean_b<-r$mean_b/(i-1)
r$mean_c<-r$mean_c/(i-1)
model3
###Je souhaite faire une classification supervisé
###Je commence par utilisé un modèle de regression logistique
model <- glm(is_genuine~
margin_low + margin_up + diagonal + height_left + height_right + length,
family="binomial",data= df)
###Je supprime les variable qui nuisent à mon modèle
a<-MASS::stepAIC(model)
View(df)
View(df_cor)
df_t<-filter(df, is_genuine == TRUE)
View(df_t)
df_t<-filter(df, is_genuine == "TRUE")
View(df)
df_t<-filter(df, is_genuine == "True")
df_t<-filter(df, is_genuine == "False")
View(df_t)
df_t<-filter(df, is_genuine == "True")
df_f<-filter(df, is_genuine == "False")
###Je test la normalité de mes données
shapiro.test(df_t$diagonal)
shapiro.test(df_t$height_left)
shapiro.test(df_t$height_right)
shapiro.test(df_t$margin_low)
shapiro.test(df_t$margin_up)
shapiro.test(df_t$length)
###Je test la normalité de mes données
shapiro.test(df_f$diagonal)
shapiro.test(df_f$height_left)
shapiro.test(df_f$height_right)
shapiro.test(df_f$margin_up)
shapiro.test(df_f$length)
View(model2)
library(dplyr)
library(FactoMineR)
library(factoextra)
library(gridExtra)
library(corrplot)
library(caret)
library(MASS)
library(tibble)
library(ggpubr)
select <- dplyr::select
###Je récupère les données
df<-read.csv("billets.csv", encoding = "UTF-8")
###Je trace les courbe de densité des billets pour chaque variable
u<-ggplot(df, aes(diagonal))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(diagonal)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
v<-ggplot(df, aes(height_right))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(height_right)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
w<-ggplot(df, aes(height_left))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(height_left)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
x<-ggplot(df, aes(margin_low))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(margin_low)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
y<-ggplot(df, aes(margin_up))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(margin_up)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
z<-ggplot(df, aes(length))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(length)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
grid.arrange(u,v,w,x,y,z, ncol=2, nrow = 3)
###Je test la normalité de mes données
shapiro.test(df$diagonal)
shapiro.test(df$height_left)
shapiro.test(df$height_right)
shapiro.test(df$margin_low)
shapiro.test(df$margin_up)
shapiro.test(df$length)
###je réalise la matrice des corrélation de ces variables
df_cor<-select(df,-"is_genuine")
cormat <- cor(df_cor, method = "pearson")
p.mat <- cor.mtest(df_cor)$p
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD",
"#4477AA"))
corrplot(cormat, method = "color", col = col(200),
type = "full", order = "original", number.cex = .7,
addCoef.col = "black", # Add coefficient of correlation
tl.col = "black", tl.srt = 90, # Text label color and rotation
# Combine with significance
p.mat = p.mat, sig.level = 0.05,
# hide correlation coefficient on the principal diagonal
diag = FALSE)
###J'observe les liens entre mes variables les plus corrélées
a<-ggplot(df, aes(height_left, height_right))+geom_point()+
geom_smooth(method = lm)
b<-ggplot(df, aes(height_right,margin_low))+geom_point()+
geom_smooth(method = lm)
c<-ggplot(df, aes(length, margin_low))+geom_point()+
geom_smooth(method = lm)
d<-ggplot(df, aes(length, margin_up))+geom_point()+
geom_smooth(method = lm)
grid.arrange(a,b,c,d, ncol=2, nrow = 2)
###J'effectue une pca sur l'ensemble de mes données
res.pca <- PCA(df_cor, graph = FALSE, scale.unit = TRUE, ncp = 3)
###J'observe le pourcentage de variance expliquée de chacun de mes
###axes obtenue par pca
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))
###Je choisis d'oberver 3 plans (axe 1 et 2 // 2 et 3 // 1 et 3)
###cercle de corrélation du premier plan
fviz_pca_var(res.pca)
###premier plan (1 et 2)
fviz_pca_ind(res.pca,geom.ind = "point", col.ind = df$is_genuine)
###cercle de corrélation du deuxieme plan
fviz_pca_var(res.pca, axes = c(2,3))
###premier plan (2 et 3)
fviz_pca_ind(res.pca,geom.ind = "point", col.ind = df$is_genuine,
axes = c(2,3))
###cercle de corrélation du troisième plan
fviz_pca_var(res.pca, axes = c(1,3))
###troisieme plan (1 et 3)
fviz_pca_ind(res.pca,geom.ind = "point", col.ind = df$is_genuine,
axes = c(1,3))
###contribution des individus pour chacun des axes 1,2 et 3
contrib<-res.pca$ind$contrib%>%as.data.frame()
###contribution des variables pour chacun des axes 1,2 et 3
contrib_var<-res.pca$var$contrib%>%as.data.frame()
###J'observe mes billets dans le plan length margin_low
###Les différentes pca me font penser que ce plan devrait
###séparer de façon efficace les vraies et les faux billets
ggplot(df, aes(length, margin_low))+geom_point(aes(colour = df$is_genuine))
clr<-cbind(df,contrib)%>%select(is_genuine,Dim.1)%>%
arrange(desc(Dim.1))
clr$is_genuine<-as.numeric(clr$is_genuine)+2
clr2<-cbind(df,contrib)%>%select(is_genuine,Dim.2)%>%
arrange(desc(Dim.2))
clr2$is_genuine<-as.numeric(clr2$is_genuine)+2
###Je calcul la contribution des billets pour mes axe 1 et 2
### de ma pca
fviz_contrib(res.pca, choice="ind", axes = 1, top = Inf,
fill = clr$is_genuine, color = clr$is_genuine)
###False en vert, True en bleu
fviz_contrib(res.pca, choice="ind", axes = 2, top = Inf,
fill = clr2$is_genuine, color = clr2$is_genuine)
###J'effectue une classification non supervisé à l'aide de la fonction
###HCPC ( cah + kmeans)
res.pca <- PCA(df_cor, graph = FALSE, scale.unit = TRUE, ncp = 6)
res.hcpc <- HCPC(res.pca, graph = FALSE, nb.par = 200, nb.clust = 2)
fviz_dend(res.hcpc,
k = 2,
cex = 0.7,                     # Taille du text
palette = "jco",               # Palette de couleur ?ggpubr::ggpar
rect = TRUE, rect_fill = TRUE, # Rectangle autour des groupes
rect_border = "jco",           # Couleur du rectangle
labels_track_height = 0.8      # Augment l'espace pour le texte
)
fviz_cluster(res.hcpc,
show.clust.cent = TRUE, # Show cluster centers
palette = "jco",         # Color palette see ?ggpubr::ggpar
ggtheme = theme_minimal(),
main = "Factor map"
)
res.hcpc$data.clust$clust<-
res.hcpc$data.clust$clust%>%factor(labels = c("2","1"))
###Je calcul la réussite de cette classification
mean(res.hcpc$data.clust$clust == df$is_genuine%>%as.numeric())
res.km<-kmeans(df_cor, 2, nstart = 25)
fviz_cluster(res.km, data = df_cor,
palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
###Je calcul la réussite de cette classification
mean(res.km$cluster == df$is_genuine%>%as.numeric())
0.9823529*170
###Je souhaite faire une classification supervisé
###Je commence par utilisé un modèle de regression logistique
model <- glm(is_genuine~
margin_low + margin_up + diagonal + height_left + height_right + length,
family="binomial",data= df)
###Je supprime les variable qui nuisent à mon modèle
a<-MASS::stepAIC(model)
###je conserve margin up et low et length
###Je vais calculer le taux de réussite de mon modèle glm à 3 variables
###et le comparer à un modèle lda
###Je vais utiliser la validation croisé pour tester mes modèles
i = 1
r = data.frame(mean_a = 0, mean_b = 0, mean_c = 0)
for (i in 1 : 1000) {
training.samples <- df$is_genuine %>%
createDataPartition(p = 0.7, list = FALSE)
train.data <- df[training.samples, ]
test.data <- df[-training.samples, ]
# Estimate preprocessing parameters
preproc.param <- train.data %>%
preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)
# Fit the model
model1 <- lda(is_genuine~., data = train.transformed)
# Make predictions
predictions <- model1 %>% predict(test.transformed)
# Model accuracy
a<-mean(predictions$class==test.transformed$is_genuine)
# Fit the model
model2 <- glm(is_genuine~ length + margin_low + margin_up,
family="binomial",data= train.transformed)
probabilities <- model2 %>% predict(test.transformed, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "True", "False")
b<-mean(predicted.classes == test.transformed$is_genuine)
# Fit the model
model3 <- glm(is_genuine~ .,family="binomial",data= train.transformed)
probabilities <- model3 %>% predict(test.transformed, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "True", "False")
c<-mean(predicted.classes == test.transformed$is_genuine)
r$mean_a<-r$mean_a + a
r$mean_b<-r$mean_b + b
r$mean_c<-r$mean_c + c
i = i+1
}
r$mean_a<-r$mean_a/(i-1)
r$mean_b<-r$mean_b/(i-1)
r$mean_c<-r$mean_c/(i-1)
###J'affiche les résultats
###LDA : Nbre de fois ou lda est meilleur
###length_margin : nbre de fois ou glm est meilleur
###egal: égalité // mean_a réussite LDA // mean_b réussite glm
r
model1
model2
model3
df_t<-filter(df, is_genuine == "True")
df_f<-filter(df, is_genuine == "False")
###Je test la normalité de mes données
shapiro.test(df_t$diagonal)
shapiro.test(df_t$height_left)
shapiro.test(df_t$height_right)
shapiro.test(df_t$margin_low)
shapiro.test(df_t$margin_up)
shapiro.test(df_t$length)
###Je test la normalité de mes données
shapiro.test(df_f$diagonal)
shapiro.test(df_f$height_left)
shapiro.test(df_f$height_right)
shapiro.test(df_f$margin_low)
shapiro.test(df_f$margin_up)
shapiro.test(df_f$length)
###Je sauvegarde mes objets
save(model1, model2, preproc.param, file = "model")
