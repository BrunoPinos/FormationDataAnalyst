geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(pop_diff)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
shapiro.test(df$pop_diff)
z<-ggplot(df, aes(prot_ani_prct))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(prot_ani_prct)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
shapiro.test(df$prot_ani_prct)
v<-ggplot(df, aes(pib))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(pib)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
shapiro.test(df$pib)
###On rejette l'hypothèse nulle au seuil de 1%
###Les variables retenues sont kcal et prot
#J'affiche les courbe de densité de chacune des variables
grid.arrange(w,x,y,z,v, ncol=2, nrow = 3)
#J'extrait les pays de mes groupes dans 5 table différentes
df_1<-df%>%filter(clust == "pays sous développés")%>%
select(-"clust")
df_2<-df%>%filter(clust == "pays en transition")%>%
select(-"clust")
df_3<-df%>%filter(clust == "pays à forte démographie")%>%
select(-"clust")
df_4<-df%>%filter(clust == "autres")%>%
select(-"clust")
df_5<-df%>%filter(clust == "occident")%>%
select(-"clust")
#J'observe la dispersion de mes groupes selon la variable kcal
ggplot(df, aes(x = clust, y = kcal, fill = clust))+
geom_boxplot()+
theme(legend.position="none")+
stat_summary(fun.y=mean, geom="point", shape=4, size=2)+
scale_x_discrete(limits=c("pays sous développés",
"pays en transition",
"autres",
"pays à forte démographie",
"occident"))+ coord_flip()
#je construit les courbes de densitée pour kcal des 2 groupes
x1<-ggplot(filter(df, clust == "pays en transition"), aes(kcal))+
geom_histogram(aes(y=..density..), bins = 10,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(kcal)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
x2<-ggplot(filter(df, clust == "pays sous développés"), aes(kcal))+
geom_histogram(aes(y=..density..), bins = 10,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(kcal)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
#J'éffectue un test de normalité pour kcal sur les 2 groupes
shapiro.test(filter(df, clust == "pays sous développés")$kcal)
shapiro.test(filter(df, clust == "pays en transition")$kcal)
#j'affiche les courbes
grid.arrange(x1,x2, ncol=2, nrow = 1)
###Test de fisher (variance)
var.test(df_1$kcal, df_2$kcal)
###p-value = 0.09905 les variances sont différentes au seuil de 10%
#Je choisis le groupe occident et je réalise une pca par rapport
#au variable pop_diff et pib
df_table_5<-df_5
row.names(df_table_5)<-df_table_5$Zone
df_table_5<-select(df_table_5,"pib","pop_diff")
res.pca <- PCA(df_table_5, graph = FALSE)
fviz_pca_var(res.pca,repel = TRUE)
fviz_pca_ind(res.pca, col.ind = "x")
#J'établis la liste des pays du plus intéressant au moins intéressant
#pour nous.
#La variable x est un mélange égal de la variable pib et de la
#variable pop_diff
pays_liste<-res.pca[["ind"]][["coord"]]%>%as.data.frame()
pays_liste$Zone<-rownames(pays_liste)
pays_liste<-pays_liste%>%select(Zone, Dim.1)%>%arrange(desc(Dim.1))
pays_liste
shapiro.test(df_1$kcal)
shapiro.test(df_2$kcal)
library(dplyr)
library(FactoMineR)
library(factoextra)
library(gridExtra)
select<-dplyr::select
#J'importe les données de la FAO et je sélectionne les colonnes
#qui m'intéresse
pop_2008<-read.csv("pop_2008.csv", encoding = "UTF-8")%>%
select("Zone", "pop2008" = "Valeur")
setwd("C:/Users/Bruno/Desktop/ouvrablesFormations/Parcours_data_analyst/P5_pinos_bruno/data")
setwd("C:/Users/Bruno/Desktop/ouvrablesFormations/Parcours_data_analyst/P5_pinos_bruno")
setwd("../data")
setwd(".../data")
setwd("..fr./data")
getwd()
setwd("/data")
setwd("./data")
#J'importe les données de la FAO et je sélectionne les colonnes
#qui m'intéresse
pop_2008<-read.csv("pop_2008.csv", encoding = "UTF-8")%>%
select("Zone", "pop2008" = "Valeur")
getwd()
setwd("./data")
getwd()
setwd("./data")
setwd("./P5_pinos_bruno/data")
setwd("~/P5_pinos_bruno/data")
setwd("~/data")
setwd("./data")
tinytex::install_tinytex()
library(dplyr)
library(FactoMineR)
library(factoextra)
library(gridExtra)
library(corrplot)
library(caret)
library(MASS)
library(tibble)
library(ggpubr)
select <- dplyr::select
###Je récupère les données
df<-read.csv("billets.csv", encoding = "UTF-8")
###Je trace les courbe de densité des billets pour chaque variable
u<-ggplot(df, aes(diagonal))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(diagonal)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
v<-ggplot(df, aes(height_right))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(height_right)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
w<-ggplot(df, aes(height_left))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(height_left)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
x<-ggplot(df, aes(margin_low))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(margin_low)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
y<-ggplot(df, aes(margin_up))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(margin_up)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
z<-ggplot(df, aes(length))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(length)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
grid.arrange(u,v,w,x,y,z, ncol=2, nrow = 3)
###Je test la normalité de mes données
shapiro.test(df$diagonal)
shapiro.test(df$height_left)
shapiro.test(df$height_right)
shapiro.test(df$margin_low)
shapiro.test(df$margin_up)
shapiro.test(df$length)
###je réalise la matrice des corrélation de ces variables
df_cor<-select(df,-"is_genuine")
cormat <- cor(df_cor, method = "pearson")
p.mat <- cor.mtest(df_cor)$p
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD",
"#4477AA"))
corrplot(cormat, method = "color", col = col(200),
type = "full", order = "original", number.cex = .7,
addCoef.col = "black", # Add coefficient of correlation
tl.col = "black", tl.srt = 90, # Text label color and rotation
# Combine with significance
p.mat = p.mat, sig.level = 0.05,
# hide correlation coefficient on the principal diagonal
diag = FALSE)
###J'observe les liens entre mes variables les plus corrélées
a<-ggplot(df, aes(height_left, height_right))+geom_point()+
geom_smooth(method = lm)
b<-ggplot(df, aes(height_right,margin_low))+geom_point()+
geom_smooth(method = lm)
c<-ggplot(df, aes(length, margin_low))+geom_point()+
geom_smooth(method = lm)
d<-ggplot(df, aes(length, margin_up))+geom_point()+
geom_smooth(method = lm)
grid.arrange(a,b,c,d, ncol=2, nrow = 2)
###J'effectue une pca sur l'ensemble de mes données
res.pca <- PCA(df_cor%>%select(-"height_right"), graph = FALSE, scale.unit = TRUE, ncp = 3)
###J'observe le pourcentage de variance expliquée de chacun de mes
###axes obtenue par pca
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))
###Je choisis d'oberver 3 plans (axe 1 et 2 // 2 et 3 // 1 et 3)
###cercle de corrélation du premier plan
fviz_pca_var(res.pca)
###premier plan (1 et 2)
fviz_pca_ind(res.pca,geom.ind = "point", col.ind = df$is_genuine)
###cercle de corrélation du deuxieme plan
fviz_pca_var(res.pca, axes = c(2,3))
###premier plan (2 et 3)
fviz_pca_ind(res.pca,geom.ind = "point", col.ind = df$is_genuine,
axes = c(2,3))
###cercle de corrélation du troisième plan
fviz_pca_var(res.pca, axes = c(1,3))
###troisieme plan (1 et 3)
fviz_pca_ind(res.pca,geom.ind = "point", col.ind = df$is_genuine,
axes = c(1,3))
###contribution des individus pour chacun des axes 1,2 et 3
contrib<-res.pca$ind$contrib%>%as.data.frame()
###contribution des variables pour chacun des axes 1,2 et 3
contrib_var<-res.pca$var$contrib%>%as.data.frame()
###J'observe mes billets dans le plan length margin_low
###Les différentes pca me font penser que ce plan devrait
###séparer de façon efficace les vraies et les faux billets
ggplot(df, aes(length, margin_low))+geom_point(aes(colour = df$is_genuine))
clr<-cbind(df,contrib)%>%select(is_genuine,Dim.1)%>%
arrange(desc(Dim.1))
clr$is_genuine<-as.numeric(clr$is_genuine)+2
clr2<-cbind(df,contrib)%>%select(is_genuine,Dim.2)%>%
arrange(desc(Dim.2))
clr2$is_genuine<-as.numeric(clr2$is_genuine)+2
###Je calcul la contribution des billets pour mes axe 1 et 2
### de ma pca
fviz_contrib(res.pca, choice="ind", axes = 1, top = Inf,
fill = clr$is_genuine, color = clr$is_genuine)
###False en vert, True en bleu
fviz_contrib(res.pca, choice="ind", axes = 2, top = Inf,
fill = clr2$is_genuine, color = clr2$is_genuine)
###J'effectue une classification non supervisé à l'aide de la fonction
###HCPC ( cah + kmeans)
res.pca <- PCA(df_cor,
graph = FALSE, scale.unit = TRUE, ncp = 3)
res.hcpc <- HCPC(res.pca, graph = FALSE, nb.par = 200, nb.clust = 2)
fviz_dend(res.hcpc,
k = 2,
cex = 0.7,                     # Taille du text
palette = "jco",               # Palette de couleur ?ggpubr::ggpar
rect = TRUE, rect_fill = TRUE, # Rectangle autour des groupes
rect_border = "jco",           # Couleur du rectangle
labels_track_height = 0.8      # Augment l'espace pour le texte
)
fviz_cluster(res.hcpc,
show.clust.cent = TRUE, # Show cluster centers
palette = "jco",         # Color palette see ?ggpubr::ggpar
ggtheme = theme_minimal(),
main = "Factor map"
)
res.hcpc$data.clust$clust<-
res.hcpc$data.clust$clust%>%factor(labels = c("2","1"))
###Je calcul la réussite de cette classification
mean(res.hcpc$data.clust$clust == df$is_genuine%>%as.numeric())
res.km<-kmeans(df_cor, 2, nstart = 25)
fviz_cluster(res.km, data = df_cor,
palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
###Je calcul la réussite de cette classification
mean(res.km$cluster == df$is_genuine%>%as.numeric())
a<-table(res.km$cluster-1, df$is_genuine%>%as.numeric()-1)
confusionMatrix(pred, actual, positive = "TRUE")
pred<-(res.km$cluster-1)%>%as.logical()%>%as.factor()
actual<-df$is_genuine%>%as.logical()%>%as.factor()
actual[actual == TRUE]%>%length()
pred
confusionMatrix(pred, actual, positive = "TRUE")
actual[actual == TRUE]%>%length()
library(dplyr)
library(FactoMineR)
library(factoextra)
library(gridExtra)
library(corrplot)
library(caret)
library(MASS)
library(tibble)
library(ggpubr)
select <- dplyr::select
###Je récupère les données
df<-read.csv("billets.csv", encoding = "UTF-8")
###Je trace les courbe de densité des billets pour chaque variable
u<-ggplot(df, aes(diagonal))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(diagonal)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
v<-ggplot(df, aes(height_right))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(height_right)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
w<-ggplot(df, aes(height_left))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(height_left)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
x<-ggplot(df, aes(margin_low))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(margin_low)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
y<-ggplot(df, aes(margin_up))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(margin_up)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
z<-ggplot(df, aes(length))+
geom_histogram(aes(y=..density..), bins = 30,
colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")+
geom_vline(aes(xintercept=mean(length)),
color="blue", linetype="dashed", size=1)+
theme(axis.text.y = element_blank())
grid.arrange(u,v,w,x,y,z, ncol=2, nrow = 3)
###Je test la normalité de mes données
shapiro.test(df$diagonal)
shapiro.test(df$height_left)
shapiro.test(df$height_right)
shapiro.test(df$margin_low)
shapiro.test(df$margin_up)
shapiro.test(df$length)
###je réalise la matrice des corrélation de ces variables
df_cor<-select(df,-"is_genuine")
cormat <- cor(df_cor, method = "pearson")
p.mat <- cor.mtest(df_cor)$p
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD",
"#4477AA"))
corrplot(cormat, method = "color", col = col(200),
type = "full", order = "original", number.cex = .7,
addCoef.col = "black", # Add coefficient of correlation
tl.col = "black", tl.srt = 90, # Text label color and rotation
# Combine with significance
p.mat = p.mat, sig.level = 0.05,
# hide correlation coefficient on the principal diagonal
diag = FALSE)
###J'observe les liens entre mes variables les plus corrélées
a<-ggplot(df, aes(height_left, height_right))+geom_point()+
geom_smooth(method = lm)
b<-ggplot(df, aes(height_right,margin_low))+geom_point()+
geom_smooth(method = lm)
c<-ggplot(df, aes(length, margin_low))+geom_point()+
geom_smooth(method = lm)
d<-ggplot(df, aes(length, margin_up))+geom_point()+
geom_smooth(method = lm)
grid.arrange(a,b,c,d, ncol=2, nrow = 2)
###J'effectue une pca sur l'ensemble de mes données
res.pca <- PCA(df_cor%>%select(-"height_right"), graph = FALSE, scale.unit = TRUE, ncp = 3)
###J'observe le pourcentage de variance expliquée de chacun de mes
###axes obtenue par pca
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))
###Je choisis d'oberver 3 plans (axe 1 et 2 // 2 et 3 // 1 et 3)
###cercle de corrélation du premier plan
fviz_pca_var(res.pca)
###premier plan (1 et 2)
fviz_pca_ind(res.pca,geom.ind = "point", col.ind = df$is_genuine)
###cercle de corrélation du deuxieme plan
fviz_pca_var(res.pca, axes = c(2,3))
###premier plan (2 et 3)
fviz_pca_ind(res.pca,geom.ind = "point", col.ind = df$is_genuine,
axes = c(2,3))
###cercle de corrélation du troisième plan
fviz_pca_var(res.pca, axes = c(1,3))
###troisieme plan (1 et 3)
fviz_pca_ind(res.pca,geom.ind = "point", col.ind = df$is_genuine,
axes = c(1,3))
###contribution des individus pour chacun des axes 1,2 et 3
contrib<-res.pca$ind$contrib%>%as.data.frame()
###contribution des variables pour chacun des axes 1,2 et 3
contrib_var<-res.pca$var$contrib%>%as.data.frame()
###J'observe mes billets dans le plan length margin_low
###Les différentes pca me font penser que ce plan devrait
###séparer de façon efficace les vraies et les faux billets
ggplot(df, aes(length, margin_low))+geom_point(aes(colour = df$is_genuine))
clr<-cbind(df,contrib)%>%select(is_genuine,Dim.1)%>%
arrange(desc(Dim.1))
clr$is_genuine<-as.numeric(clr$is_genuine)+2
clr2<-cbind(df,contrib)%>%select(is_genuine,Dim.2)%>%
arrange(desc(Dim.2))
clr2$is_genuine<-as.numeric(clr2$is_genuine)+2
###Je calcul la contribution des billets pour mes axe 1 et 2
### de ma pca
fviz_contrib(res.pca, choice="ind", axes = 1, top = Inf,
fill = clr$is_genuine, color = clr$is_genuine)
###False en vert, True en bleu
fviz_contrib(res.pca, choice="ind", axes = 2, top = Inf,
fill = clr2$is_genuine, color = clr2$is_genuine)
###J'effectue une classification non supervisé à l'aide de la fonction
###HCPC ( cah + kmeans)
res.pca <- PCA(df_cor,
graph = FALSE, scale.unit = TRUE, ncp = 3)
res.hcpc <- HCPC(res.pca, graph = FALSE, nb.par = 200, nb.clust = 2)
fviz_dend(res.hcpc,
k = 2,
cex = 0.7,                     # Taille du text
palette = "jco",               # Palette de couleur ?ggpubr::ggpar
rect = TRUE, rect_fill = TRUE, # Rectangle autour des groupes
rect_border = "jco",           # Couleur du rectangle
labels_track_height = 0.8      # Augment l'espace pour le texte
)
fviz_cluster(res.hcpc,
show.clust.cent = TRUE, # Show cluster centers
palette = "jco",         # Color palette see ?ggpubr::ggpar
ggtheme = theme_minimal(),
main = "Factor map"
)
res.hcpc$data.clust$clust<-
res.hcpc$data.clust$clust%>%factor(labels = c("2","1"))
###Je calcul la réussite de cette classification
mean(res.hcpc$data.clust$clust == df$is_genuine%>%as.numeric())
res.km<-kmeans(df_cor, 2, nstart = 25)
fviz_cluster(res.km, data = df_cor,
palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
###Je calcul la réussite de cette classification
mean(res.km$cluster == df$is_genuine%>%as.numeric())
a<-table(res.km$cluster-1, df$is_genuine%>%as.numeric()-1)
pred<-(res.km$cluster-1)%>%as.logical()%>%as.factor()
actual<-df$is_genuine%>%as.logical()%>%as.factor()
actual[actual == TRUE]%>%length()
confusionMatrix(pred, actual, positive = "TRUE")
###Je souhaite faire une classification supervisé
###Je commence par utilisé un modèle de regression logistique
model <- glm(is_genuine~
margin_low + margin_up + diagonal + height_left + height_right + length,
family="binomial",data= df)
###Je supprime les variable qui nuisent à mon modèle
a<-MASS::stepAIC(model)
###je conserve margin up et low et length
###Je vais calculer le taux de réussite de mon modèle glm à 3 variables
###et le comparer à un modèle lda
###Je vais utiliser la validation croisé pour tester mes modèles
pred_a<-c()
pred_b<-c()
pred_c<-c()
actual<-c()
i = 1
r = data.frame(mean_a = 0, mean_b = 0, mean_c = 0)
for (i in 1 : 1000) {
training.samples <- df$is_genuine %>%
createDataPartition(p = 0.7, list = FALSE)
train.data <- df[training.samples, ]
test.data <- df[-training.samples, ]
# Estimate preprocessing parameters
preproc.param <- train.data %>%
preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)
###reference pour la matrice de confusion
actual<-c(actual,test.transformed$is_genuine)
# Fit the model
model1 <- lda(is_genuine~., data = train.transformed)
# Make predictions
predictions <- model1 %>% predict(test.transformed)
# Model accuracy
a<-mean(predictions$class==test.transformed$is_genuine)
# prediction du model1 pour la matrice de confusion
pred_a<-(c(pred_a, predictions$class)-1)%>%as.logical()%>%as.factor()
# Fit the model
model2 <- glm(is_genuine~ length + margin_low + margin_up,
family="binomial",data= train.transformed)
probabilities <- model2 %>% predict(test.transformed, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "True", "False")
b<-mean(predicted.classes == test.transformed$is_genuine)
# prediction du model1 pour la matrice de confusion
pred_b<-c(pred_b%>%as.logical(),
predicted.classes%>%as.logical())%>%as.logical()%>%as.factor()
# Fit the model
model3 <- glm(is_genuine~ .,family="binomial",data= train.transformed)
probabilities <- model3 %>% predict(test.transformed, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "True", "False")
c<-mean(predicted.classes == test.transformed$is_genuine)
# prediction du model1 pour la matrice de confusion
pred_c<-c(pred_c%>%as.logical(),
predicted.classes%>%as.logical())%>%as.logical()%>%as.factor()
r$mean_a<-r$mean_a + a
r$mean_b<-r$mean_b + b
r$mean_c<-r$mean_c + c
i = i+1
}
