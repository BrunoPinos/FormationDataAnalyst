---
title: "P8_code_02"
author: "brunop31"
date: "09/09/2020"
output: html_document
---

```{r, warning=FALSE, message = FALSE}
library(ggplot2)
library(dplyr)
library(factoextra)
library(FactoMineR)
library(corrplot)
library(caret)
library(MASS)
library(car)
library(numbers)
library(randomForest)
library(nnet)

select<-dplyr::select
set.seed(1)
```

```{r}
#Je récupère les données
df_all<-read.csv(
  "Dendris.csv",
  encoding = "UTF-8", sep = ",", dec = ".")%>%select(-"X")

#Je calcule la valeur max de mes données
df_all%>%select(-"Souche")%>%max

#Je calcule combien il y a de 0 dans mes données
df_all[df_all==0]%>%length()/(nrow(df_all)*ncol(df_all))

#Je compte combien il y a d'échantillon par souche
souche<-df_all%>%group_by(Souche)%>%count()

#Je construis les boxplot de mes variables
boxplot.matrix(df_all%>%select(-"Souche")%>%as.matrix(),
               use.cols = TRUE)

#J'applique la fonction X -> log(X+1) à mes données
mat_log<-df_all%>%select(-"Souche")%>%
  apply(c(1,2), function(x) log10(x+1)%>%round(2))

#Je construit les boxplot de mes variables après la transformation logarithmique
boxplot.matrix(mat_log,use.cols = TRUE)

#Je crée une table avec les valeurs log transformées
df_log<-cbind(df_all$Souche,mat_log%>%as.data.frame())%>%
  rename("Souche" = "df_all$Souche")

#Je calcul le max de cette table
df_log%>%select(-"Souche")%>%max
```

```{r}
#Je fais un tableau recap de mes sonde (mediane par souche)
df_median<-df_log%>%group_by(Souche)%>%summarise_all(median)

df_median[,2:ncol(df_log)]<-df_median[,2:ncol(df_log)]%>%round(2)

#Je fais un tableau recap de mes sonde (moyenne par souche)
df_mean<-df_log%>%group_by(Souche)%>%summarise_all(mean)

df_mean[,2:ncol(df_log)]<-df_mean[,2:ncol(df_log)]%>%round(2)

#Je construit un tableau qui calcul le taux d'allumage des sondes par souche
df_01<-df_log%>%select(-"Souche")
df_01[df_01!=0]<-1
df_01<-cbind(df_log$Souche, df_01)%>%rename("Souche" = "df_log$Souche")


df_allume<-df_01%>%group_by(Souche)%>%summarise_all(mean)
df_allume[,-1]<-df_allume[,-1]%>%round(2)
sum<-apply(df_allume%>%select(-"Souche"),1,sum)
df_allume<-cbind(sum,df_allume)

head(df_mean)
head(df_median)
head(df_allume)
```

```{r}
###je réalise la matrice des corrélation de mes variables les plus corrélées

cormat <- cor(df_log%>%select(-"Souche"), 
              method = "pearson")%>%as.data.frame()

x<-which(abs(cormat)>0.9, arr.ind = TRUE)%>%as.data.frame()%>%
  filter(row != col)

x<-rbind(matrix(x$col),matrix(x$row))%>%as.data.frame()%>%
  distinct()%>%as.matrix()


customers_cor<-df_log%>%select(-"Souche")%>%.[,x]

cormat <- cor(customers_cor, method = "pearson")

p.mat <- cor.mtest(customers_cor)$p

col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD",
                          "#4477AA"))

corrplot(cormat, method = "color", col = col(200),
         type = "full", order = "hclust", number.cex = .7,
         addCoef.col = "black", # Add coefficient of correlation
         tl.col = "black", tl.srt = 90, # Text label color and rotation
         # Combine with significance
         p.mat = p.mat, sig.level = 0.05, 
         # hide correlation coefficient on the principal diagonal
         diag = FALSE)
```
```{r}
###J'effectue une PCA
df_pca<-PCA(df_log%>%select(-"Souche"), graph = FALSE)

###J'observe le pourcentage de variance expliquée de chacun de mes
###axes obtenue par pca
fviz_eig(df_pca, addlabels = TRUE, ylim = c(0, 50))
```

```{r}
###cercle de corrélation du premier plan
fviz_pca_var(df_pca)
```

```{r}
###premier plan (1 et 2) 
fviz_pca_ind(df_pca,geom.ind = "point", col.ind = df_log$Souche)

```

```{r}
#Je fais un kmeans clustering
k11<-kmeans(df_log%>%select(-"Souche"), 11, 25)

fviz_cluster(k11, df_log%>%select(-"Souche"),
show.clust.cent = TRUE, # Show cluster centers
ggtheme = theme_minimal(),
main = "Factor map"
)

```
```{r}
#Je réorganise les groupes de mon kmeans et calcul sa précision
factor(k11$cluster)

mean(df_all$Souche%>%as.numeric()==factor(
  k11$cluster,labels = c(4,8,7,6,10,3,2,5,9,1,11))%>%
  as.vector()%>%as.numeric())
```

```{r, message = FALSE, results='hide'}
#J'effectue 100 cross-validations pour les 5 modèles choisis 
#avec mes données en log

####################Test des 5 modèles choisis en log#######################

b1 = c()
b2 = c()
b3 = c()
b4 = c()
b5 = c()
c = c()

i = 1

for (i in 1 : 100) {

#Je partitionne mes données de façon égalitaire pour chaque souche
#en 2, une partition test et une entrainement
training.samples <- df_log$Souche %>%
  createDataPartition(p = 0.7, list = FALSE)

samp<-training.samples[,1]

train.data <- df_log[training.samples, ]

test.data <- df_log[-training.samples, ]

var_0<-which(apply(select(train.data,-"Souche"), 2, var)==0)%>%
  as.data.frame()%>%select(num = ".")%>%mutate(sonde = row.names(.))

train.data<-select(train.data, -var_0$sonde)
test.data<-select(test.data, -var_0$sonde)

# Estimate preprocessing parameters
preproc.param <- train.data %>% 
  preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)

df.transformed<-rbind(train.transformed,test.transformed)

################### Fit the model1 LDA ###########################

#J'entraine le modèle
model1 <- lda(Souche~., data = train.transformed)

#Je fais une prédiction sur la partition test 
predictions <- model1 %>% predict(test.transformed)

#Je stock les prédictions
b1<-c(b1, predictions$class%>%as.vector())

################### Fit the model2 RDA ###########################
model2 <- klaR::rda(Souche~., data = train.transformed)

predictions <- model2 %>% predict(test.transformed)

b2<-c(b2, predictions$class%>%as.vector())

################# Fit the model3 Random forest########################
model3 <- randomForest(Souche ~., train.transformed, mtry = 5,
                       ntree = 1500)

b3<-c(b3, predict(model3, test.transformed)%>%as.vector())

###############Fit the model4 nnet #################################
model4 <- nnet(Souche ~., train.transformed, size = 50,
               rang = 0.5,decay = 5e-10, maxit = 50,
              MaxNWts = 100000, abstol = 1)

predictions<-model4 %>% predict(test.transformed)

x<-colnames(predictions)[apply(predictions, 1, which.max)]

b4<-c(b4, x)

#################Fit the model5 multinom ##########################
model5 <- multinom(Souche ~., train.transformed)

b5<-c(b5, predict(model5, test.transformed)%>%as.vector())

#################################################################

#Je récupère les étiquettes
c<-c(c,test.data$Souche%>%as.vector())

i = i+1
}
```

```{r}
#Je construit les matrices de confusions
conf1<-confusionMatrix(b1%>%as.factor(), c%>%as.factor())
conf2<-confusionMatrix(b2%>%as.factor(), c%>%as.factor())
conf3<-confusionMatrix(b3%>%as.factor(), c%>%as.factor())
conf4<-confusionMatrix(b4%>%as.factor(), c%>%as.factor())
conf5<-confusionMatrix(b5%>%as.factor(), c%>%as.factor())


conf1
conf2
conf3
conf4
conf5
```

```{r,  message = FALSE, results='hide'}
#J'effectue 100 cross-validations pour les 5 modèles choisis 
#avec mes données sans le log

####################Test des 5 modèles choisis sans log#############

b1 = c()
b2 = c()
b3 = c()
b4 = c()
b5 = c()
c = c()

i = 1

for (i in 1 : 10) {

training.samples <- df_all$Souche %>%
  createDataPartition(p = 0.7, list = FALSE)

samp<-training.samples[,1]

train.data <- df_all[training.samples, ]

test.data <- df_all[-training.samples, ]

var_0<-which(apply(select(train.data,-"Souche"), 2, var)==0)%>%
  as.data.frame()%>%select(num = ".")%>%mutate(sonde = row.names(.))

train.data<-select(train.data, -var_0$sonde)
test.data<-select(test.data, -var_0$sonde)

# Estimate preprocessing parameters
preproc.param <- train.data %>% 
  preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)

df.transformed<-rbind(train.transformed,test.transformed)

################### Fit the model1 LDA ###########################
model1 <- lda(Souche~., data = train.transformed)
# Make predictions
predictions <- model1 %>% predict(test.transformed)

b1<-c(b1, predictions$class%>%as.vector())

################### Fit the model2 RDA ###########################
model2 <- klaR::rda(Souche~., data = train.transformed)
# Make predictions
predictions <- model2 %>% predict(test.transformed)

b2<-c(b2, predictions$class%>%as.vector())

################# Fit the model3 Random forest########################
model3 <- randomForest(Souche ~., train.transformed, mtry = 5,
                       ntree = 1500)

b3<-c(b3, predict(model3, test.transformed)%>%as.vector())

###############Fit the model4 nnet #################################
model4 <- nnet(Souche ~., train.transformed, size = 50,
               rang = 0.5,decay = 5e-10, maxit = 50,
              MaxNWts = 1000000, abstol = 1)

predictions<-model4 %>% predict(test.transformed)

x<-colnames(predictions)[apply(predictions, 1, which.max)]

b4<-c(b4, x)

#################Fit the model5 multinom ##########################
model5 <- multinom(Souche ~., train.transformed)

b5<-c(b5, predict(model5, test.transformed)%>%as.vector())

#################################################################

c<-c(c,test.data$Souche%>%as.vector())

i = i+1
}

```

```{r}
conf1<-confusionMatrix(b1%>%as.factor(), c%>%as.factor())
conf2<-confusionMatrix(b2%>%as.factor(), c%>%as.factor())
conf3<-confusionMatrix(b3%>%as.factor(), c%>%as.factor())
conf4<-confusionMatrix(b4%>%as.factor(), c%>%as.factor())
conf5<-confusionMatrix(b5%>%as.factor(), c%>%as.factor())


conf1
conf2
conf3
conf4
conf5
```

```{r}
#Je test mes modèles sur de nouveaux échantillons

##############Test sur de nouveaux échantillons####################
df_test<-read.csv("echantillon.csv",encoding = "UTF-8",
                  sep = ",",dec = ".")%>%select(-"X")

mat_log<-df_test%>%select(-"Souche")%>%
  apply(c(1,2), function(x) log10(x+1)%>%round(2))


df_logtest<-cbind(df_test$Souche,mat_log%>%as.data.frame())%>%
  rename("Souche" = "df_test$Souche")



################### Fit the model1 LDA ###########################
model1 <- lda(Souche~., data = df_log)
# Make predictions
predictions <- model1 %>% predict(df_logtest)

b1<-predictions$class%>%as.vector()

################### Fit the model2 RDA ###########################
model2 <- klaR::rda(Souche~., data = df_log)
# Make predictions
predictions <- model2 %>% predict(df_logtest)

b2<-predictions$class%>%as.vector()

################# Fit the model3 Random forest########################
model3 <- randomForest(Souche ~., df_log, mtry = 5,
                       ntree = 1500, importance = TRUE)

b3<-predict(model3, df_logtest)%>%as.vector()

###############Fit the model4 nnet #################################
model4 <- nnet(Souche ~., df_log, size = 50,
               rang = 0.5,decay = 5e-10, maxit = 50,
              MaxNWts = 1000000, abstol = 1)

predictions<-model4 %>% predict(df_logtest)

x<-colnames(predictions)[apply(predictions, 1, which.max)]

b4<-x

#################Fit the model5 multinom ##########################
model5 <- multinom(Souche ~., df_log)

b5<-predict(model5, df_logtest)%>%as.vector()

#################################################################

c<-df_test$Souche%>%as.vector()

conf1<-confusionMatrix(b1%>%as.factor(), c%>%as.factor())
conf2<-confusionMatrix(b2%>%as.factor(), c%>%as.factor())
conf3<-confusionMatrix(b3%>%as.factor(), c%>%as.factor())
conf4<-confusionMatrix(b4%>%as.factor(), c%>%as.factor())
conf5<-confusionMatrix(b5%>%as.factor(), c%>%as.factor())


conf1
conf2
conf3
conf4
conf5
```

```{r}
#Je trie mes données par importance avec random forest

imp<-importance(model3)%>%as.data.frame()

head(imp)

#Je trace les barplot des 10 sondes les plus importantes pour chaque souches 
par(mfrow = c(3,4))

for (i in 1:11) {
  names10<-imp%>%arrange(desc(imp[,i]))%>%row.names()%>%.[1:10]
  
  imp10<-imp%>%arrange(desc(imp[,i]))%>%.[1:10,i]%>%round(3)
  plot(imp10,type="h",ylab="Importance",xlab="Sondes",xaxt = "n")
  title(main = colnames(imp)[i], pch=16, cex.main=1, line = 0.5)
  points(imp10,pch=20)
  axis(1,at=1:10,labels=names10,cex.axis=1,las=3)
}
```



```{r}
#Je construit un graphe donnant l'efficacité de mon modèle en cross-v
#pour plusieurs nombres de variable
rfProfile <- rfe(Souche~., df_log,
                 size = c(seq(12,40,4)),
                 maximize = TRUE,
                 rfeControl = rfeControl(
                    functions = rfFuncs, method = "repeatedcv",
                    repeats = 10)
                 )

plot(rfProfile, type = c("o", "g"))

rfProfile$optVariables
```



```{r}
#je récupère les sondes optimal pour mon modèle à 40 sondes
rfProfile <- rfe(Souche~., df_log,
                 size = c(40),
                 maximize = FALSE,
                 rfeControl = rfeControl(
                    functions = rfFuncs, method = "repeatedcv",
                    repeats = 10)
                 )


rfProfile$optVariables
```
```{r}
#Je test mon modèle à 40 sonde en cross validation 100 fois
#(rfe est trop long je n'ai testé que 10 fois)

df_opt<-df_log%>%select(c("Souche",rfProfile$optVariables))

####################Test des 5 modèles choisis en log#######################
b6 = c()
c = c()

i = 1

for (i in 1 : 100) {

training.samples <- df_opt$Souche %>%
  createDataPartition(p = 0.7, list = FALSE)

samp<-training.samples[,1]

train.data <- df_opt[training.samples, ]

test.data <- df_opt[-training.samples, ]

var_0<-which(apply(select(train.data,-"Souche"), 2, var)==0)%>%
  as.data.frame()%>%select(num = ".")%>%mutate(sonde = row.names(.))

train.data<-select(train.data, -var_0$sonde)
test.data<-select(test.data, -var_0$sonde)

# Estimate preprocessing parameters
preproc.param <- train.data %>% 
  preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)

df.transformed<-rbind(train.transformed,test.transformed)

################# Fit the model3 Random forest########################
model6 <- randomForest(Souche ~., train.transformed, mtry = 5,
                       ntree = 1500)

b6<-c(b6, predict(model6, test.transformed)%>%as.vector())


#################################################################

c<-c(c,test.data$Souche%>%as.vector())

i = i+1
}


conf6<-confusionMatrix(b6%>%as.factor(), c%>%as.factor())

conf6
```

```{r}
#Je test mon nouveau modèle sur les nouveaux échantillons
model6 <- randomForest(Souche ~., df_opt, mtry = 5,
                       ntree = 1500, importance = TRUE)

b6<-predict(model6, df_logtest)%>%as.vector()

c<-df_logtest$Souche%>%as.vector()

conf6<-confusionMatrix(b6%>%as.factor(), c%>%as.factor())

conf6
```


