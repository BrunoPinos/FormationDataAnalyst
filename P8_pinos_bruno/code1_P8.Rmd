---
title: "code_P8"
author: "brunop31"
date: "02/09/2020"
output: html_document
---

```{r, warning=FALSE}
library(ggplot2)
library(dplyr)
library(factoextra)
library(FactoMineR)
library(corrplot)
library(caret)
library(MASS)
library(car)
library(numbers)

select<-dplyr::select

```

```{r}
df_all<-read.csv(
  "donnee_dendris.csv",
  encoding = "UTF-8", sep = ",", dec = ".")

#On supprime la colonne qui donne le numéro de ligne
df_all<-df_all[,-1]

#On regarde s'il manque des données
head(which(is.na(df_all), arr.ind = TRUE))

#On remplace quand c'est possibme par la médiane de samp du même groupe
df_all[195,11]<-median(filter(df_all, Souche == "Spn")[,11],na.rm = TRUE)

#On supprime quand ce n'est pas possible
df_all<-df_all[-182,]

#On réorganise les lignes
row.names(df_all)<-1:263

#On a plus de valeurs manquantes
head(which(is.na(df_all), arr.ind = TRUE))

###on supprime les sondes disfonctionnelle
sonde_force<-apply(df_all%>%select(-"Souche"), 2, sum)%>%as.data.frame()%>%
  rename("sum" = ".")

sonde_force$col<-2:69

x<-which(df_all != 0, arr.ind = TRUE)%>%
  as.data.frame()%>%group_by(col)%>%count()%>%
  full_join(data.frame(col = 1:69))

x<-x[-1,]  
x[is.na(x)]<-0

#Après examen des sondes j'ai supprimé les pire(j'ai préféré enlever 4 que 5)
df_all<-df_all[,-c(35,62,3,24,2,17,27,30,31,4)]
```

```{r}
#Test de normalité
pvalue<-c()
sonde<-c()
for (i in 2:36) {
 x<-shapiro.test(df_all[,i])
  pvalue[i-1]<-x$p.value
  sonde[i-1]<-colnames(df_all)[i]
}

#Les variables ne sont clairement pas normalement distribuées

gauss<-cbind(sonde,pvalue)%>%data.frame()
gauss$pvalue<-gauss$pvalue%>%as.vector()%>%as.numeric()

#J'analyse mes sondes
ggplot(df_all, aes(Souche, df_all$X7, fill = Souche, colour = Souche)) +
  geom_jitter(width=0.25)+
        geom_boxplot(alpha=0.5, outlier.shape=NA,)+  
        xlab(label = "Type of car") +
        ylab(label = "Highway miles per gallon") +
        theme(axis.text.x = element_text(angle=30, hjust=1, vjust=1))+
        theme(legend.position="none")+
        theme_classic()+
        ggtitle("Boxplot avec les observations")

#Je fais un tableau recap de mes sonde (mediane nombre de sonde allumé)

df_median<-df_all%>%group_by(Souche)%>%summarise_all(median)

df_01<-df_all%>%select(-"Souche")
df_01[df_01!=0]<-1
df_01<-cbind(df_all$Souche, df_01)%>%rename("Souche" = "df_all$Souche")

df_allume<-df_01%>%group_by(Souche)%>%summarise_all(median)
df_allume[,-1]<-df_allume[,-1]%>%round(2)
sum<-apply(df_allume%>%select(-"Souche"),1,sum)
df_allume<-cbind(sum,df_allume)


#On supprime les sondes X14, X108, et X81 sont spécifique à aucune souche
df_all<-df_all%>%select(-c("X14","X108", "X81"))

#Les sondes X24,X25,X26,X170 sont spécifique au mpn ne pas les enlever
```
```{r}
#Je fais un tableau recap de mes sonde (mediane nombre de sonde allumé)

df_median<-df_all%>%group_by(Souche)%>%summarise_all(median)

df_01<-df_all%>%select(-"Souche")
df_01[df_01!=0]<-1
df_01<-cbind(df_all$Souche, df_01)%>%rename("Souche" = "df_all$Souche")

df_allume2<-df_01%>%group_by(Souche)%>%summarise_all(mean)
df_allume2[,-1]<-df_allume2[,-1]%>%round(2)
sum<-apply(df_allume2%>%select(-"Souche"),1,sum)
df_allume2<-cbind(sum,df_allume2)
```

```{r}
outlier<-c()
for (i in 1:nrow(df_all)) {
j<-df_all$Souche[i]%>%as.numeric()

x<-((df_all[i,-1])!=0)%>%as.numeric()*2-1

z<-sum((df_allume2[j,-c(1:2)]*3-1)*x)

outlier<-c(outlier,z)
}

outlier<-outlier%>%as.data.frame()%>%cbind(df_all$Souche,.)%>%
  rename("Souche" = "df_all$Souche")

moyenne<-outlier%>%group_by(Souche)%>%summarise(mean = mean(.))

outlier<-full_join(outlier,moyenne)%>%mutate(score = ./mean)
```

```{r}
#Les échantillon sain n'accroche normalement pas les sondes et les autres si

#Je vérifie en sommant par ligne

somme<-df_all%>%select(-"Souche")%>%apply(1,sum)%>%
  as.data.frame()%>%rename("sum" = ".")
somme$samp<-row.names(somme)%>%as.numeric()
somme$X<-df_all$Souche
somme<-somme%>%arrange(sum)
row.names(somme)<-1:nrow(somme)
somme$rank<-row.names(somme)

ggplot(somme, aes(X, sum, fill = X, colour = X)) +
  geom_jitter(width=0.25)+
        geom_boxplot(alpha=0.5, outlier.shape=NA,)+  
        xlab(label = "Type of car") +
        ylab(label = "Highway miles per gallon") +
        theme(axis.text.x = element_text(angle=30, hjust=1, vjust=1))+
        theme(legend.position="none")+
        theme_classic()+
        ggtitle("Boxplot avec les observations")


#J'ai des MCA avec un score de 0 et xneg avec un score de 69789
#c'est échantillon sont des outlier je les supprime
#Un pa est vraiment très fort après analyse je le supprime aussi

df_all<-df_all[-c(95,96,263),]
```

```{r}
###je supprime les variables trop corrélées
cormat <- cor(df_all%>%select(-"Souche"), 
              method = "pearson")%>%as.data.frame()


which(abs(cormat)>0.8, arr.ind = TRUE)%>%as.data.frame()%>%
  filter(row != col)%>%filter(
    !(row.names(.) %in% c("X62","X68","X70","X72","X83","X87","X27",
                          "X29","X35","X171","X172","X173",
                          "X51","X169","X118","X6","X29","X89","X170",
                          "X143","X102","X110","X84","X164","X25","X26")))


#which.max(sonde_force[colnames(df_all)[c(28,29,30,33,38,42,43,50,1)+1]])

df<-df_all%>%select(-"Souche")%>%
  select(-c("X62","X68","X70","X72","X83","X87","X27",
            "X29","X35","X171","X172","X173",
            "X51","X169","X118","X6","X29","X89","X170",
            "X143","X102","X110","X84","X84","X164","X25","X26"))

cormat <- cor(df, method = "pearson")%>%as.data.frame()

which(abs(cormat)>0.8, arr.ind = TRUE)%>%as.data.frame()%>%
  filter(row != col)

df<-cbind(df_all$Souche,df)%>%rename("Souche" = "df_all$Souche")

#Je fais un tableau recap de mes sonde (mediane nombre de sonde allumé)

df_median<-df%>%group_by(Souche)%>%summarise_all(median)

df_01<-df%>%select(-"Souche")
df_01[df_01!=0]<-1
df_01<-cbind(df$Souche, df_01)%>%rename("Souche" = "df$Souche")

df_allume<-df_01%>%group_by(Souche)%>%summarise_all(mean)
df_allume[,-1]<-df_allume[,-1]%>%round(2)
sum<-apply(df_allume%>%select(-"Souche"),1,sum)
df_allume<-cbind(sum,df_allume)

###J'effectue une PCA
df_pca<-PCA(df%>%select(-"Souche"), graph = FALSE)

###J'observe le pourcentage de variance expliquée de chacun de mes
###axes obtenue par pca
fviz_eig(df_pca, addlabels = TRUE, ylim = c(0, 50))
```

```{r}
###cercle de corrélation du premier plan
fviz_pca_var(df_pca)
```

```{r}
###premier plan (1 et 2) 
fviz_pca_ind(df_pca,geom.ind = "point", col.ind = df$Souche)

#Des groupes apparraissent mais la concentration virale étale mais groupe
#en ligne
```

```{r}
#Je fais un kmeans clustering
k11<-kmeans(df%>%select(-"Souche"), 11, 25)

fviz_cluster(k11, df%>%select(-"Souche"),
show.clust.cent = TRUE, # Show cluster centers
ggtheme = theme_minimal(),
main = "Factor map"
)

#Le kmeans manque clairement de précision 60% de prédiction
```

```{r}
###Recherche outlier isolation forest
pred<-data.frame()
for (i in df$Souche%>%levels()) {
  x<-filter(df, Souche == i)%>%select(-"Souche")
  iso<-isotree::isolation.forest(x, ntrees = 100, nthreads = 1,
                                 ndim =1)
  y<-predict(iso, x)%>%as.data.frame()
  y$Souche<-i
  pred<-pred%>%rbind(y)
}

#Aucun point ne semble vraiment étrange

###test robustesse LDA
robust<-rrcov::Wilks.test(Souche~., data = df)

#lambda faible et pvalue faible bonne robustesse de la lda

###Recherche outlier par test lda

b1 = c()

c = c()

i = 1

for (i in 1 : 10) {

################### Fit the model1 LDA ###########################
model1 <- lda(Souche~., data = df)
# Make predictions
predictions <- model1 %>% predict(df)

b1<-c(b1, predictions$class%>%as.vector())

c<-c(c,df$Souche%>%as.vector())

i = i+1
}

error1<-which(b1 != c)%>%mod(259)%>%as.data.frame()%>%
  rename("samp" = "." )%>%group_by(samp)%>%
  count()


#Après analyse les points qui créent des erreurs ne semblent pas être
#des outlier. Je ne vais pas enlever 34 points !
```

```{r}
b1 = c()
b2 = c()

c = c()

i = 1

for (i in 1 : 100) {

training.samples <- df_log$Souche %>%
  createDataPartition(p = 0.7, list = FALSE)

samp<-training.samples[,1]

train.data <- df_log[training.samples, ]

test.data <- df_log[-training.samples, ]

var_0<-which(apply(select(train.data,-"Souche"), 2, var)==0)%>%
  as.data.frame()%>%select(num = ".")%>%mutate(sonde = row.names(.))

train.data<-select(train.data, -var_0$sonde)
test.data<-select(test.data, -var_0$sonde)

# Estimate preprocessing parameters
preproc.param <- train.data %>% 
  preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)

df.transformed<-rbind(train.transformed,test.transformed)

################### Fit the model2 RDA ###########################
model2 <- klaR::rda(Souche~., data = train.transformed)
# Make predictions
predictions <- model2 %>% predict(test.transformed)

b2<-c(b2, predictions$class%>%as.vector())

#############################################################
c<-c(c,test.data$Souche%>%as.vector())

i = i+1
}

conf2<-confusionMatrix(b2%>%as.factor(), c%>%as.factor())

conf2

#Grâce à la rda moins sensible aux données atypique j'obtient un taux de
#réussite de 90%
```

```{r}
save(df_all, file = "df_all")
save(df, file ="df")
```





