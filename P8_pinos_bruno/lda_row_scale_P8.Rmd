---
title: "code_P8"
author: "brunop31"
date: "02/09/2020"
output: html_document
---

```{r, warning=FALSE}
library(ggplot2)
library(dplyr)
library(factoextra)
library(FactoMineR)
library(corrplot)
library(caret)
library(MASS)
library(car)
library(numbers)

select<-dplyr::select

```

```{r}
df_all<-read.csv(
  "donnee_dendris.csv",
  encoding = "UTF-8", sep = ",", dec = ".")

#On supprime la colonne qui donne le numéro de ligne
df_all<-df_all[,-1]

#On regarde s'il manque des données
head(which(is.na(df_all), arr.ind = TRUE))

#On remplace quand c'est possibme par la médiane de samp du même groupe
df_all[195,11]<-median(filter(df_all, Souche == "Spn")[,11],na.rm = TRUE)

#On supprime quand ce n'est pas possible
df_all<-df_all[-182,]

#On réorganise les lignes
row.names(df_all)<-1:263

#On a plus de valeurs manquantes
head(which(is.na(df_all), arr.ind = TRUE))

###on supprime les sondes disfonctionnelle
sonde_force<-apply(df_all%>%select(-"Souche"), 2, sum)%>%as.data.frame()%>%
  rename("sum" = ".")

sonde_force$col<-2:69

x<-which(df_all != 0, arr.ind = TRUE)%>%
  as.data.frame()%>%group_by(col)%>%count()%>%
  full_join(data.frame(col = 1:69))

x<-x[-1,]  
x[is.na(x)]<-0

#Après examen des sondes j'ai supprimé les pire(j'ai préféré enlever 4 que 5)
df_all<-df_all[,-c(35,62,3,24,2,17,27,30,31,4)]
```

```{r}
#Les échantillon sain n'accroche normalement pas les sondes et les autres si

#Je vérifie en sommant par ligne

somme<-df_all%>%select(-"Souche")%>%apply(1,sum)%>%
  as.data.frame()%>%rename("sum" = ".")
somme$samp<-row.names(somme)%>%as.numeric()
somme$X<-df_all$Souche
somme<-somme%>%arrange(sum)
row.names(somme)<-1:263
somme$rank<-row.names(somme)

ggplot(somme, aes(X, sum, fill = X, colour = X)) +
  geom_jitter(width=0.25)+
        geom_boxplot(alpha=0.5, outlier.shape=NA,)+  
        xlab(label = "Type of car") +
        ylab(label = "Highway miles per gallon") +
        theme(axis.text.x = element_text(angle=30, hjust=1, vjust=1))+
        theme(legend.position="none")+
        theme_classic()+
        ggtitle("Boxplot avec les observations")


#J'ai des MCA avec un score de 0 et xneg avec un score de 69789
#c'est échantillon sont des outlier je les supprime
#Un pa est vraiment très fort après analyse je le supprime aussi

df_all<-df_all[-c(95,96,263,158),]
```

```{r}
###je supprime les variables trop corrélées
cormat <- cor(df_all%>%select(-"Souche"), 
              method = "pearson")%>%as.data.frame()

which(abs(cormat)>0.8, arr.ind = TRUE)%>%as.data.frame()%>%
  filter(row != col)%>%filter(
    !(col %in% c(16,53,56,9,27,36,40,26,28,41,1,11,2,57,58,19,54,46,
                 10,52,43,18,35)))%>%
  filter(!(row %in%c(16,53,56,9,27,36,40,26,28,41,1,11,2,57,58,19,54,46,
                 10,52,43,18,35)))

#which.max(sonde_force[colnames(df_all)[c(28,29,30,33,38,42,43,50,1)+1]])

df<-df_all%>%select(-"Souche")%>%
  select(-c(16,53,56,9,27,36,40,26,28,41,1,11,2,57,58,19,54,46,
                 10,52,43,18,35))

df<-cbind(df_all$Souche,df)%>%rename("Souche" = "df_all$Souche")

###J'effectue une PCA
df_pca<-PCA(df%>%select(-"Souche"), graph = FALSE)

###J'observe le pourcentage de variance expliquée de chacun de mes
###axes obtenue par pca
fviz_eig(df_pca, addlabels = TRUE, ylim = c(0, 50))
```

```{r}
###cercle de corrélation du premier plan
fviz_pca_var(df_pca)
```

```{r}
###premier plan (1 et 2) 
fviz_pca_ind(df_pca,geom.ind = "point", col.ind = df$Souche)

#Des groupes apparraissent mais la concentration virale étale mais groupe
#en ligne
```
```{r}
###Recherche outlier isolation forest
pred<-data.frame()
for (i in df_row_scale$Souche%>%levels()) {
  x<-filter(df_row_scale, Souche == i)%>%select(-"Souche")
  iso<-isotree::isolation.forest(x, ntrees = 100, nthreads = 1,
                                 ndim =1)
  y<-predict(iso, x)%>%as.data.frame()
  y$Souche<-i
  pred<-pred%>%rbind(y)
}
```

```{r}
b1 = c()
b2 = c()

c = c()

i = 1

for (i in 1 : 10) {

training.samples <- df$Souche %>%
  createDataPartition(p = 0.7, list = FALSE)

samp<-training.samples[,1]

train.data <- df[training.samples, ]

test.data <- df[-training.samples, ]

var_0<-which(apply(select(train.data,-"Souche"), 2, var)==0)%>%
  as.data.frame()%>%select(num = ".")%>%mutate(sonde = row.names(.))

train.data<-select(train.data, -var_0$sonde)
test.data<-select(test.data, -var_0$sonde)

# Estimate preprocessing parameters
preproc.param <- train.data %>% 
  preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)

df.transformed<-rbind(train.transformed,test.transformed)

################### Fit the model1 LDA ###########################
model1 <- lda(Souche~., data = train.transformed)
# Make predictions
predictions <- model1 %>% predict(test.transformed)

b1<-c(b1, predictions$class%>%as.vector())

################### Fit the model2 RDA ###########################
model2 <- klaR::rda(Souche~., data = train.transformed)
# Make predictions
predictions <- model2 %>% predict(test.transformed)

b2<-c(b2, predictions$class%>%as.vector())

#############################################################
c<-c(c,test.data$Souche%>%as.vector())

i = i+1
}
conf1<-confusionMatrix(b1%>%as.factor(), c%>%as.factor())
conf2<-confusionMatrix(b2%>%as.factor(), c%>%as.factor())

conf1
conf2
```


```{r}
############################################################################
###On scale les lignes
###On doit retirer les xneg qui ne présente pas de problème de concentration

df_pos<-df%>%filter(Souche != "Xneg")
  
df_row_scale<-df_pos%>%select(-"Souche")%>%
  apply(1, scale)%>%t()%>%
  as.data.frame()%>%cbind(df_pos$Souche,.)


colnames(df_row_scale)<-colnames(df)

###je supprime les variables trop corrélées des row_scale
cormat <- cor(df_row_scale%>%select(-"Souche"),
              method = "pearson")%>%as.data.frame()

which(abs(cormat)>0.8, arr.ind = TRUE)%>%as.data.frame()%>%
  filter(row != col)%>%filter(
    !(col %in% c(4,14,8)))%>%
  filter(!(row %in% c(4,14,8)))

df_row_scale<-df_row_scale%>%select(-c(5,15,9))

df_row_scale$Souche<-df_row_scale$Souche%>%factor()
```

```{r}
###J'effectue une PCA
df_pca<-PCA(df_row_scale%>%select(-"Souche"), graph = FALSE)

###J'observe le pourcentage de variance expliquée de chacun de mes
###axes obtenue par pca
fviz_eig(df_pca, addlabels = TRUE, ylim = c(0, 50))
```

```{r}
###cercle de corrélation du premier plan
fviz_pca_var(df_pca)
```

```{r}
###premier plan (1 et 2) 
fviz_pca_ind(df_pca,geom.ind = "point",
             col.ind = df_pos$Souche)

```

```{r}
###premier plan (1 et 3) 
fviz_pca_ind(df_pca,geom.ind = "point", axes = c(2,3),
             col.ind = df_pos$Souche)

#Les différents groupes sont plus visibles
```

```{r}
#Je fais un kmeans clustering
k11<-kmeans(df_row_scale%>%select(-"Souche"), 10, 25)

fviz_cluster(k11, df_row_scale%>%select(-"Souche"),
show.clust.cent = TRUE, # Show cluster centers
ggtheme = theme_minimal(),
main = "Factor map"
)
```
```{r}
#Je calcul le taux de réussite d'une prédiction par kmeans
k11$cluster

mean(df_row_scale$Souche%>%as.numeric()==factor(
  k11$cluster,labels = c(5,8,6,1,4,7,9,2,10,3))%>%
  as.vector()%>%as.numeric())

predictions<-factor(
  k11_row_scale$cluster,labels =
    df$Souche%>%as.factor()%>%levels()%>%.[c(9,5,4,1,3,8,11,7,10,2,6)])%>%
  as.vector()%>%as.factor()

confusionMatrix(df$Souche%>%as.factor(),
                predictions)
#Le kmeans ne différencie pas les xneg les xneg et les pa/ les spn et mpn
```

```{r}
b1 = c()
b2 = c()

c = c()

i = 1

for (i in 1 : 10) {

training.samples <- df_row_scale$Souche %>%
  createDataPartition(p = 0.7, list = FALSE)

samp<-training.samples[,1]

train.data <- df_row_scale[training.samples, ]

test.data <- df_row_scale[-training.samples, ]

var_0<-which(apply(select(train.data,-"Souche"), 2, var)==0)%>%
  as.data.frame()%>%select(num = ".")%>%mutate(sonde = row.names(.))

train.data<-select(train.data, -var_0$sonde)
test.data<-select(test.data, -var_0$sonde)

# Estimate preprocessing parameters
preproc.param <- train.data %>% 
  preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)

df.transformed<-rbind(train.transformed,test.transformed)

################### Fit the model1 LDA ###########################
model1 <- lda(Souche~., data = train.transformed)
# Make predictions
predictions <- model1 %>% predict(test.transformed)

b1<-c(b1, predictions$class%>%as.vector())

################### Fit the model2 RDA ###########################
model2 <- klaR::rda(Souche~., data = train.transformed)
# Make predictions
predictions <- model2 %>% predict(test.transformed)

b2<-c(b2, predictions$class%>%as.vector())

#############################################################
c<-c(c,test.data$Souche%>%as.vector())

i = i+1
}
conf1<-confusionMatrix(b1%>%as.factor(), c%>%as.factor())
conf2<-confusionMatrix(b2%>%as.factor(), c%>%as.factor())

conf1
conf2
```
